%%%      1         2         3         4         5         6         7        8
%%% 567890123456789012345678901234567890123456789012345687901234567890123456790
%%%

\svnInfo $Id$

\newcommand\schema[1]{\ensuremath{\mathcal{#1}}}
\newcommand\relation[1]{\ensuremath{\textnormal{\bf\textsf{#1}}}}

\makeatletter
\newcommand\skyline{\mathop{\operator@font skyline}\nolimits}
\newcommand\skyband{\mathop{\operator@font skyband}\nolimits}
\makeatother

\newcommand\imp{\Rightarrow}
\newcommand\bigland{\bigwedge}
\newcommand\biglor{\bigvee}
\newcommand\union{\cup}
\newcommand\bigunion{\bigcup}
\newcommand\intersection{\cap}
\newcommand\difference{\backslash}
\newcommand\dominates{\ensuremath{\succ}\xspace}
\newcommand\domanatedby{\ensuremath{\prec}\xspace}
\newcommand\weakdominates{\ensuremath{\succeq}\xspace}

\newcommand\inlinesql[1]{{\tt #1}}
\newcommand\srcref[1]{{\tt #1}}
\newcommand\postgresdocu[2]{\href{http://www.postgresql.org/docs/8.3/static/#1}{#2}\footnote{\url{http://www.postgresql.org/docs/8.3/static/#1}}}
\newcommand\ttbackslash{{\char92}}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{property}{Property}

\newcommand\nt[1]{\textit{#1}}

\makeatletter
\newenvironment{interactive}
{%
\newcommand\shprompt[1]{\$\ {\textbf{##1}}}
\newcommand\sqlprompt[1]{db=\# {\textbf{##1}}}
\newcommand\sqlpromptcont[1]{db-\# {\textbf{##1}}}
\newcommand\comment[1]{{\rmfamily\textit{##1}}}
\newcommand\rcomment[1]{\hfill\comment{##1}}
\begingroup\small\list{}{\listparindent 0\p@\itemindent\listparindent\leftmargin15\p@\rightmargin15\p@}\item[]\begin{alltt}}{\end{alltt}\endlist\endgroup}

\newdimen\onecolumnwidth
\global\onecolumnwidth\textwidth
\advance\onecolumnwidth -\columnsep
\divide\onecolumnwidth\tw@
\newsavebox\tempbox

\makeatother

\newcommand\subplotprofile[2][todo]{%
\subfloat[#1]{%
\includegraphics[width=\onecolumnwidth]{plots-profile/#2}}%
}%

\newcommand\subplotlabeledprofile[3]{%
\subfloat[#1]{%
\includegraphics[width=\onecolumnwidth]{plots-profile/#2}%
\label{#3}%
}}%

\lstdefinelanguage{pseudo}{
	language=C,
	mathescape=true, 
	literate={:=}{{$\gets$}}1, 
	morekeywords={function,begin,end,foreach,then}
}



%%%
%%% CHAPTER: TODO
%%%



\chapter{TODO}

\section{TODO}
\begin{itemize}
\item \todo{casing of section headings?}{}
\item \todo{ask ali, which website for travelling by airplane uses skyline}{}
\item \todo{has the order in which the skyline dimensions are checked an effect?}{}
\item \todo{show how Preference SQL ABOUT can be emulated}{}
\end{itemize}



%%%
%%% CHAPTER: Introduction
%%%



\chapter{Introduction}
\label{chap:introduction}

\section{General Introduction}
\label{sec:generalintroduction}
When thinking of a \emph{skyline} images like
Figure~\ref{fig:vienneseskyline} might come to ones mind, the
popularity of such photographs is illustrated by following figures:
\emph{Goolge images} returns $\approx 3{,}580{,}000$ hits, not
counting the hits for the Nissan's skyline sports car, for the search
term
\emph{skyline -nissan}, and 
%
\href{http://www.istockphoto.com/}{istockphoto.com}, 
a popular collection of member-generated royalty-free images websites,
has $\approx 25{,}000$ photos in the stock for the search term
\emph{skyline}, as of May 23 2008. 
% http://www.merriam-webster.com/cgi-bin/dictionary?book=Dictionary&va=skyline
The Merriam-Webster's online dictionary gives following definition for \emph{skyline}:
\begin{enumerate}
\item the apparent juncture of earth and sky: \emph{horizon}
\item an outline (as of buildings or a mountain range) against the
background of the sky
\end{enumerate}


\begin{figure}[htbp]
% this is from: 
% http://www.istockphoto.com/file_closeup/where/scenics/cityscapes/
% 2358169_lightning_traffic_over_danube_bridge_and_vienna_skyline.php
% ?id=2358169
%
% Photographers Description:
%
% viennese skyline with cars driving on a street shot by night with a
% long time exposure. I added high contrast, therefore image gets very
% little grainy.
%
\centering
\includegraphics[scale=1.0]{photos/iStock_000002358169Large_100mm}%
\caption{Viennese skyline (nightshot with long exposure time, 
taken by Franz Pflügl / Vienna)}%
\label{fig:vienneseskyline}%
\end{figure}

From a more abstract point of view a skyline is made up of objects
(buildings, maintains and such) which do not have another object
closer and taller to the eye of the beholder. If we are only
interested in the objects that are ``touching the sky'', we consider
only the tallest object in each direction of view. On the other hand
if we care about visiblity, an object is visible as long as there is
no object closer and taller. We ask the alerted reader to excuse the
simplifications we made here, the authors are aware of the concept of
perspective projection and of the fact that the earth is not a disk.
%However, we will shortly see how this intuition matches a precise
%mathematical definition and a concept in the real of databases.

\bigskip
In the realm of database systems the \emph{skyline operator} is
important for supporting multi-criteria decision making applications.
Given a set of $d$-dimensional data points, the \emph{skyline}
consists of the points, called \emph{skyline points}, which are not
{\em dominated} by another data point. One data point $r$ dominates
another data $s$ point if it is at least has good as $s$ in all
dimensions and better in at least one.
\citet{Borzsonyi2001} proposed a {\em skyline} extension of the SQL
syntax with this form:

\begin{sql}
SELECT ... FROM ... WHERE ... \\
GROUP BY ... HAVING ...       \\
SKYLINE OF \textnormal{[}DISTINCT\textnormal{]} $a_1$ \textnormal{[}MIN$|$MAX$|$DIFF\textnormal{]}, ..., $a_m$ \textnormal{[}MIN$|$MAX$|$DIFF\textnormal{]} \\
ORDER BY ...
\end{sql}

Computing the skyline is also known as the \emph{maximum vector
problem} \citep{Kung1975, Preparata1985}. The terms \emph{skyline} and
\emph{skyline operator} in the realm of databases were coined by
\citet{Borzsonyi2001}. The following examples give a motivation why 
\emph{skyline operator} is a good name for this type of
\emph{preference queries}, they also illustrate the usage of the
\inlinesql{DIFF} and \inlinesql{DISTINCT} keyword.

In figure~\ref{fig:threeDskyline} the yellow arrow indicates the
direction of view and the colored cuboids should illustrate
buildings. Table~\ref{tab:threeDskyline} shows the coordinate of the
lower left edge of each building and gives them names ($a, b,
\ldots$). The same color indicates the same $x$ coordinate. For $y$ we
have only to cases \emph{front} and
\emph{back}.

\begin{example}[Which buildings are touching the sky?]\label{ex:touchsky}
For sure building $c$ (the green in the backline) and building $f$
(the blue one in the frontline) are part of the answer and $d$ and $e$
are not.  As $a$ and $b$ do have the same height, we could take them
both or make an arbitrary choice amoung $a$ and $b$.  We will later
see that this tacking both or choose an arbitrary one can be
influenced by the keyword \inlinesql{DISTINCT}. So overall, possible
answers are $\{a, c, f\}$, $\{b, c, f\}$, or $\{a, b, c, f\}$.
\end{example}

\begin{figure}[htbp]
\centering
\includegraphics[width=100mm]{plots-misc/PlotSkyline3D}%
\caption{Skyline of buildings}%
\label{fig:threeDskyline}%
\end{figure}

\begin{table}[htbp]
\centering
\begin{tabular}{l|rrrll}
id & x & y & z & color & row\\
\hline
$a$ & 0 & 1 & 1.5 & red & back \\
$b$ & 0 & 0 & 1.5 & red & front \\
$c$ & 1 & 1 & 1.25 & green & back \\
$d$ & 1 & 0 & 1.0 & green & front \\
$e$ & 2 & 1 & 0.5 & blue & back \\
$f$ & 2 & 0 & 0.75 & blue & front
\end{tabular}
\caption{Data for Figure~\ref{fig:threeDskyline}}
\label{tab:threeDskyline}
\end{table}

\begin{example}[Which buildings are visible?]\label{ex:visibility}
To answer this question we have also to take into account how close a
building as, i.e. the $y$ coordinate.  Building $a$ is covered by $b$
and $e$ by $f$, we will later call this property \emph{dominance}. It
is obvious that $c$ and $d$ are part of the answer. The complete
answer is $\{b, c, d, f\}$.
\end{example}

The question from example~\ref{ex:touchsky} could be formalized in the
following way:

\begin{interactive}
SELECT * FROM building SKYLINE OF x DIFF, z MAX;
\end{interactive}

\noindent
in above query $a$ and $b$ will be part of the answer, will in the following
it is up to the database system to make a choice between $a$ or $b$, as they 
are equally good:

\begin{interactive}
SELECT * FROM building SKYLINE OF DISTINCT x DIFF, z MAX;
\end{interactive}

\noindent
On the other hand the query for example~\ref{ex:visibility} looks like:

\begin{interactive}
SELECT * FROM building SKYLINE OF x DIFF, y MIN, z MAX;
\end{interactive}

\subsection{Why extending SQL?}
\begin{itemize}
\item \todo{skyline is within the expressiveness of SQL}{}
\item \todo{easier to spec. that a correleted query / sql with except}{}
\item \todo{faster to evaluate}{}
\item \todo{new optimization opportuinities}{}
\end{itemize}

\subsection{Fields of Application}
motivation: green computing: less cpu time,
less computers, less energy --> safe the planet

stocks: risk vs. costs (--> streaming skyline see [Tao2006])

example of skyline

when travelling by airplane: time vs. costs

TODO: more dim: \#stops, total dist travel by bus: \#of visited cities

it is shown on some website. which?

Credit To: Ali (room mate)

employee (salary, revenue, years in the company)



% Research Questions for this Thesis
\section{Focus of this Thesis}
\todo{}{}
\todo{We consinder only BNL, SFS and variants}{}

\todo{}{}
from \citep{Chaudhuri2006}:

Special algorithms have been proposed for the case the whole relation
fits into main memory \citep{Preparata1985}, nevertheless we do not
take them into account as memory is always a short resource in a
database scenario, either due to the number of concurrent users or
limited total main memory, e.g. on a handheld device.

The skyline operator \citep{Borzsonyi2001} filters out the
\emph{interesting} points from a potentially large set of data
points. The skyline operator returns the pareto optimal\index{pareto
optimal} elements of a set. This is also know as maximum vector
problem\index{maximum vector problem}.



%All of the algorithms are implemented as stand-alone algorithms,
In this paper, we present our work on evaluating skyline algorithms in
PostgreSQL. Building the skyline query operation in an RDBMS has
several advantages.  First, skyline can be integrated with other
relational operators, thus more sophisticated queries can be
constructed.  Moreover, no work on concurrency control and transaction
management has to be addressed.  Second, the existing index structures
such as R-trees in an RDBMS can be adapted to implement index-based
skyline algorithms.  Third, if several skyline algorithms are
available in an RDBMS, the system is able to select the most efficient
one for the given datasets.  Indeed, the comparisons of the skyline
algorithms we have so far implemented reveal that there does not exist
a clear winner in all aspects.  The efficiency of the algorithms
depend on the properties of the datasets such as dimension,
distribution, cardinality and so on.
%(more details are given in Section~\ref{sec:contribution}).
For instance, BNL is more efficient than SFS and even LESS, if the
dimension of the data is less than 5 and the number of tuples is
relatively small.

%\subsection{Our Contribution}
%\label{sec:contribution}
We have so far implemented the non-index based algorithms
BNL, SFS, and a variant of LESS in PostgreSQL.
%To the best of our knowledge, this is the first work of building
%skyline operators in an open source RDBMS. 
%\todo{there are implementations: see \cite{Chaudhuri2006, Goncalves2005, Brando2007}}
In addition, 
we extended the standard syntax to specify
\begin{itemize}
\item The treatment of NULL values (\texttt{NULLS FIRST} and \texttt{NULLS LAST})
\item The usage of order relations other than $<$ and $>$ (\texttt{USING \emph{Op}})
\item Operational aspects of skyline computation, such as 
\begin{itemize}
\item \emph{method} (BNL, SFS)
\item \emph{tuple window size} in terms of memory and/or number of slots
\item \emph{tuple window policy} (append, prepend, entropy, random)
\item \emph{usage of indexes} (\texttt{NOINDEX})
\item \emph{usage of elimination filter (EF)}
\end{itemize}
\end{itemize}

The ultimate goal of our work is building a skyline query optimizer to
automatically generate a good query plan w.r.t. I/O, time, and memory
consumption.  It is well known that the cost estimation of the skyline
queries is a non-trivial task \cite{Chaudhuri2006} since the
performance of a skyline query is sensitive to a number of parameters
\cite{Godfrey2007}.  To achieve this goal, we conducted extensive
experiments on the skyline implementations.


\section{Main Results}
\todo{}{}
We discovered several \emph{hidden rules}, which are remarkably simple
and useful, but hard to obtain from the theoretical investigation.  We
expect that our exposition of experimental results on skyline
algorithms could serve as a guideline for developing heuristics of a
skyline query optimizer, and in the meantime, provide some insight for
a deeper understanding of the skyline query characteristics.

For the purpose of repeatability we have set up a website to present
our experimental results. The source code, and the log-files from our
experiments are accessible via
\url{http://skyline.dbai.tuwien.ac.at/}.


\section{Typographical Conventions}
For interactive input and output we will show our typed input in a \texttt{\bfseries bold font}, the output \texttt{like this}, \textit{and comments like this}.


%         1         2         3         4         5         6         7         8
%12345678901234567890123456789012345678901234567890123456789012345678901234567890

\begin{interactive}
\shprompt{psql}\rcomment{start PostgreSQL interactive terminal}
\sqlprompt{SELECT * FROM a2d1e5s0 SKYLINE OF d1 MIN, d2 MIN;}\rcomment{issue a skyline query}
  id   |          d1           |          d2
-------+-----------------------+-----------------------
   417 |     0.660430708919594 |    0.0734207719527077
  1329 |    0.0486199019148477 |     0.663867116113964
...\rcomment{53 rows omitted}
 98953 |     0.136247931652335 |     0.607638615081091
(56 rows)

\sqlprompt{\ttbackslash{}q}\rcomment{quit psql}
\shprompt{}\rcomment{back at the shell prompt}
\end{interactive}

The example above also illustrates two other concepts: ``\texttt{\$}''
indicates a shell prompt and ``\texttt{db=\#}'' indicates the prompt for
PostgreSQL interactive terminal \texttt{psql}. Furthermore
``\texttt{db-\#}'' is displayed when \texttt{psql} is waiting for more
input. All of them are used throughtout the text.


\section{Further Organization}
\todo{}{}
The paper is organized as follows: In Section~\ref{sec:algorithms} we
introduce briefly the implemented skyline algorithms.
Section~\ref{sec:configuration} describes the experimental setup.
Section~\ref{sec:analysis} presents the extensive experiments over
various data settings, followed by the analysis of the
results. Section~\ref{sec:conclusion} concludes the paper and
discusses future work.



%%
%% CHAPTER: Preliminaries
%%



\chapter{Preliminaries}
\label{chap:preliminaries}

\todo{see \citep[Simkovics1998] section 1.1.1}{}

\section{Basic definitions}
\todo{We are in the context of relational model\index{relational model} of data}{\citep{Chomicki2002, Chomicki2003a}?}. As we aim at an implementation of the skyline operator into a relational database management system (RDBMS)\index{RDBMS} we restrict to finite database\index{finite database} instances.

We assume two \todo{infinite}{hm? although in a real computer is
everything finte} domains: $N$ (numbers) and $D$ (uninterpreted
constants). The domain $D$ will be used for attributes which are not
subject to skyline computation, i.e. for the travelling example we
will not use the name of the airline as a skyline criterion, therefore
$D$ will be used as domain for this attribute.  For attributes or
expressions which are subject to skyline computation we use the domain
$N$. No distinction is made between different numeric domains, since
it is not necessary for this paper. For $N$ we require that equality
($=$), inequality ($\not=$), and the binary relations $<$ (strictly
less than), $\le$ (less than or equal), $\ge$ (greater than or equal),
and $>$ (strictly greater than) are defined with the usual properties.

\begin{definition}[Schema]
Given the domains $U_i, 1 \le i \le n$, such that $U_i$ is either
equal to $D$ or $N$, we define the $n$-ary schema $\schema{R}$ as the
cartesian product of the $U_i$'s, i.e. $\schema{R} = U_1 \times U_2
\times \ldots \times U_n$. The attributes of schema \schema{R} will be
refered as $a_1, \ldots, a_n$.
\end{definition}

Preferences will be defined in terms of \emph{binary preference
relations}\index{preference relation}.
\begin{definition}[Preference relation]
Let \schema{R} be a $n$-ary schema, a relation \dominates is a
preference relation over \schema{R} if it is a subset of $\schema{R}
\times \schema{R}$.
\end{definition}

To give an intuition, \dominates will be a binary relation between pairs of tuples from the same (database) relation, we say $r$ \emph{dominates} $s$ in \dominates iff $(r, s) \in \dominates$ (or in infix notation $r \dominates s$).

We require the relation \dominates to be a \emph{strict partial
order}\index{strict partial order}, i.e. \dominates is irreflexive,
asymmetric and transitive. These properties are formalized as usual:

\begin{itemize}
\item \emph{irreflexivity:} $\forall x: x \not\dominates x$
\item \emph{asymmetry:} $\forall x, y: x \dominates y \imp y \not\dominates x$
\item \emph{transitivity:} $\forall x, y, z: (x \dominates y \land y \dominates z) \imp x \dominates z$
\end{itemize}

Non-transitive\index{non-transitive} preferences can be compute with
the BEST algorithm (\citep{Torlone2002, Ciaccia2004}), we will not
study this approach in this paper. \todo{$k$-skylines are also
non-transitive?}{}

\begin{definition}
\todo{}{}Let \relation{R} be a relation of schema \schema{R}.
\end{definition}

\begin{definition}[Skyline]
The skyline of a relation \relation{R} with respect to the preference
relation \dominates is the set of tuples $r \in \relation{R}$ which
are not dominate by any other tuple $s \in \relation{R}$, formally
$\skyline_\dominates(\relation{R}) := \{ r \in \relation{R} | \nexists
s \in \relation{R} : s \dominates r \}$
\end{definition}

\begin{lemma}
\todo{}{this is more or less theorem 2 from \citep{Chomicki2002}}
Given the relation $\relation{R} \not= \emptyset$ and \dominates a
strict parial order over \schema{R}, where \schema{R} is the schema
for \relation{R}, the skyline is non empty,
i.e. $\skyline_\dominates(\relation{R}) \not= \emptyset$ holds.
\end{lemma}


In a skyline query with the following skyline clause:
\todo{}{add space between dim and direction}
\[
\texttt{SKYLINE OF} a_1 \texttt{MIN}, \ldots, a_k \texttt{MIN}, a_{k+1} \texttt{MAX}, \ldots, a_l \texttt{MAX}, a_{l+1} \texttt{DIFF}, \ldots, a_m \texttt{DIFF}
\]
a tuple 
$r = (r_1, \ldots, r_k, r_{k+1}, \ldots, r_l, r_{l+1}, \ldots, r_m, r_{m+1}, \ldots, r_n)$
dominates a tuple
$s = (r_1, \ldots, r_k, r_{k+1}, \ldots, r_l, r_{l+1}, \ldots, r_m, r_{m+1}, \ldots, r_n)$
iff the following condition holds
\begin{eqnarray}\label{equ:skylinepf}
\left( \bigland_{1 \le i \le k} r_i \le s_i \right) \land
\left( \bigland_{k+1 \le i \le l} r_i \ge s_i \right) \land
\left( \bigland_{l+1 \le i \le m} r_i = s_i \right) \land \nonumber\\
\land
\left( \left( \biglor_{1 \le i \le k} r_i < s_i \right) \lor
       \left( \biglor_{k+1 \le i \le l} r_i > s_i \right) \right).
\end{eqnarray}

To state in an informal way, a tuple $r$ dominates a tuple $s$ if it
is equal in all \inlinesql{DIFF} dimensions, at least as good in all
\inlinesql{MIN}/\inlinesql{MAX} dimensions and better than in at least
one of the \inlinesql{MIN}/\inlinesql{MAX} dimensions.

\todo{make \dominates equal to (\ref{equ:skylinepf}) and \weakdominates equal to just the $\le$ part, use $r \sim s := r \weakdominates s \land s \weakdominates r = \forall i \in \{1, \ldots, m\}: r_i = s_i$, i.e. equal on all skyline dimensions}{}


If $\forall i \in \{1, \ldots, m\}: r_i = s_i$ holds, $r$ and $s$ are
\todo{\emph{incomparable}}{use an other term for this special case of
incomparability}, if \inlinesql{DISTINCT} is specified it is left up
to the implementation to include either $r$ or $s$ in the skyline, if
\inlinesql{DISTINCT} is not specified $r$ and $s$ are included.


In case condition (\ref{equ:skylinepf}) does not hold $r$ and $s$ are
\emph{incomparable} and may both be part of the skyline if not
dominated by any other tuple from \relation{R}.

Please note that the following subformula (\ref{equ:skylinepfdiff}) of
formula (\ref{equ:skylinepf}) induces an equality relation on
\relation{R}, i.e. \relation{R} is partitioned into groups where the
attributes $a_{l+1}, \ldots, a_m$ are equal:
\begin{equation}\label{equ:skylinepfdiff}
\bigland_{l+1 \le i \le m} r_i = s_i.
\end{equation}

\todo{As noted in \citep{Chomicki2003}, the \inlinesql{DIFF} directive works as a group by within the skyline, and the skyline for each group of diff attributes' values is found.}{rephrase}

This property can be exploited, if an ordered index on any subset of
the attributes $a_{l+1}, \ldots, a_m$ exists, since the tuple window
can be flushed each time the group is changed.

\todo{or in SFS due to the sort phase}{}, \todo{give an example with an table}{}

\subsection{Skyline as special case of winnow}
The skyline operator is a special case of the \emph{winnow
operator}\index{winnow operator} \citep{Chomicki2002}, where the
preference formula has exactly the form of formula
(\ref{equ:skylinepf}).

Since the preference relation induced by the skyline criteria is a
strict partial order, the following theorem (a special case of a
theorem in \citep{Chomicki2002}) holds:

\begin{theorem}\label{theorem:nonempty}
For every finite, nonempty instance \relation{R} of \schema{R},
$\skyline_C(\relation{R})$ is nonempty.
\end{theorem}
\todo{}{the criteria C must be clearly defined}
If the relation \relation{R} fails to be finite, it may happen that
$\skyline_C(\relation{R}) = \emptyset$, for example if \relation{R}
contains all natural numbers and the standard ordering $<$ is used.


\begin{lemma}
Let $\relation{S} = \skyline_C(\relation{R})$, it is clear that condition (\ref{equ:skylinepf}) does not for any two tuples in \relation{S}.
\end{lemma}


\subsection{Dominance and Anti-dominance regions}
dominance, anti dominance region

\todo{If a point is a skyline point can be answered by checking of the
anti domiance region is empty. This can be done with a range query
even fasilidating an index.}{}

\subsection{How our implementation differs from the mathematical model}
Our implementation of the \inlinesql{SKYLINE OF} clause is actually a
bit more flexible than the mathematical definition given above. With
our implementation the skyline operator is not restricted to
attributes with a numerical domain, it can be applied to any
attribute, as long as a \emph{sort function} is defined for the domain
in question, i.e.\/ any expression valid in a SQL \inlinesql{ORDER BY}
clause is valid as an expression in a \inlinesql{SKYLINE OF} clause.

This gives the opportunity to include expressions of almost any data
type in a skyline query, even user defined ones, since it is possible
to user define fullfledged data types in PostgreSQL. For more
information on user defined data types see PostgreSQL documentation on
\postgresdocu{xtypes.html}{User-Defined Types} and
\postgresdocu{xindex.html\#XINDEX-OPFAMILY}{Operator Classes and
Operator Families}

Anyway it is somewhat questionable what it is good for the include a
e.g. \inlinesql{VARCHAR} column in a skyline query, still it is
possible.

Furthermore our implementation allows arbitrary expressions instead of
a single attribute, e.g.

\begin{sql}
SELECT * FROM nba.players \\
SKYLINE OF (h\_feet * 12 + h\_inches) MAX NULLS LAST, weight MAX NULLS LAST
\end{sql}

\subsection{Skyline Operator is Idempotent}
We first proof a more general statement:
\begin{theorem}\label{the:skyline-idempotent}
The winnow operator is idempotent, i.e. $\omega_C(\relation
R)=\omega_C(\omega_C(\relation R))$.
\end{theorem}
\begin{proof}
\todo{no na}{}
Let $\succ$ be the preference relation induced by $C$, then the result
of the winnow operator is $\omega_C(\relation R) := \{r \in \relation
R | \nexists s \in \relation{R} : s \succ r \}$, so
$\omega_C(\relation R)$ already contains only the maximal elements
according $\succ$, \todo{...}{complete}
\end{proof}
Since the skyline operator is a special case of \emph{winnow} operator, theorem \ref{the:skyline-idempotent} holds as well.


\subsection{Independence of Attribute Order}

The following property is a well known fact about the skyline operator:

\begin{property}[Independence of Attribute Order]\label{the:attributeorder}
The semantics of the skyline operator is independent from the order
in which the attributes are specified in the query.
\end{property}
\begin{proof}
\todo{proof}{}
see equation~\ref{equ:skylinepf}
\end{proof}

To give a simple example the following query will yield the same
result:

\begin{interactive}
SELECT * FROM a15d1e5 SKYLINE OF d1 MIN, d2 MIN;
SELECT * FROM a15d1e5 SKYLINE OF d2 MIN, d1 MIN;
\end{interactive}



\subsection{Composition of Skyline Operator}
\todo{For means of simplicity we assume set semantics?}{} 

\todo{The proofs are for the non \inlinesql{SKYLINE OF DISTINCT} case}{?}.


In this section, we study serveral ways of composing the skyline
operator. (see \citep{Chomicki2002} 4.1) We assume two finite
instances \relation{R}, \relation{S} of schema \schema{R}, ...

\begin{equation}
\skyline(\relation{R} \intersection \relation{S}) = \skyline(\relation{R}) \intersection \skyline(\relation{S})
\end{equation}

this identity could be exploitet in the query optimizer. \todo{}{further work?}
is it really worth? what direction of the identity is actually iteresseting?

\begin{equation}\label{equ:skyline-composition-union}
\skyline(\relation{R} \union \relation{S}) \not= \skyline(\relation{R}) \union \skyline(\relation{S})
\end{equation}
It is easy to see that an equality in
(\ref{equ:skyline-composition-union}) would not hold, as e.g. a single
tuple $r_1$ could dominate the entire relation \relation{S}.

If the last property would hold, easy decompose, but due to theorem
(\ref{theorem:nonempty}) $skyline(\{t_1\}) = \{t_1\}$ would yield
$\forall \relation{R} : \skyline(\relation{R}) = \relation{R}$ if
decompossied to singletons.

\begin{equation}\label{equ:skyline-decompose}
\skyline(\relation{R} \union \relation{S}) = \skyline(\skyline(\relation R) \union \skyline(\relation S))
\end{equation}
\begin{proof}
\todo{copy proof from manuscript}{}
\end{proof}

This property could be of interest in a distributed setting to reduce data transfer between servers.


\begin{equation}
\skyline(\relation{R} \difference \relation{S}) \not= \skyline(\relation{R}) \difference \skyline(\relation{S})
\end{equation}

\todo{}{make this plausible}

\todo{transitive closure}{4.2}
well all skyline query are transitive, so there is no need to
investigate this here. But e.g. I prefer to eat Tafelspitz than to eat
Schnitzel, and Schnitzel over Foobar. Thus, I also prefer to eat
Tafelspitz than to eat Foobar.

\todo{skyline and joins, cross products, selections, projects, top k}{}

$\sigma_{Price<\textnormal{\euro}20}(\skyline_{C_1}(\relation{R}))=\skyline_{C_1}(\sigma_{Price<\textnormal{\euro}20}(\relation{R}))$
according to Theorem 3 (\citep{Chomicki2002}).
Such identies are not in our implementation.\todo{}{further work}

NOTE: $\sigma_{Price>\textnormal{\euro}20}$ does not commute with $\skyline$.


\texttt{TOP $k$} are realized with \inlinesql{LIMIT}

\subsection{Preference hierarchies}
(see 4.3 \citep{Chomicki2002}) ... I generally prefer red wine, but
for fish I prefer white wine.
\todo{}{I think this can not be formulated using skyline}


\subsection{Intrinsic vs. extrinsic}
According to the defintion in 5.2 \citep{Chomicki2002} the skyline
operator is \emph{intrinsic} as the preference relation between two
tuples purles on the basis of the values occurring in those
tuples. \todo{In contrast \emph{extrinsic} preference formulas may
refer not noly to build-in predicats but also to other constructs,
e.g., database relations.}{rephrase or cite}.

\subsection{Skyline Stratum and $K$-Skyband}
\todo{draw a nice diagram}{}

In the context of \emph{winnow} operator this is references as
\emph{ranking}\index{ranking}, we prefer to use the term
\emph{stratum}\index{stratum}, as we reserve the term ranking for
scoring functions (see \ref{subsec:scoring}).

The $n$th skyline startum $\skyline_C^n$ is recursifly defined as:

\begin{eqnarray}
\skyline_C^1(\relation{R}) & := & \skyline_C(\relation{R}) \\
\skyline_C^{n+1}(\relation{R}) & := & \skyline_C(\relation{R} \difference \bigunion_{1 \le i \le n} \skyline_C^i(\relation{R}))
\end{eqnarray}

To give an example, the query $\skyline_C^2(\relation{R})$ computes the set of ``second-best'' tuples.\todo{}{rephrase or cite}

The startum are of interest especially if there is a single
\emph{killer tuple} or very few tuples which are dominating the entire
dataset.  In the context of the relation \emph{Hotel(Price, Distance
to beach)}, a barrack on the beach is cheaper and closer to the beach
than any other accommodation, but might to meet our
standards. \todo{restaurat, close, good, tiered of eating there}{}

A \emph{$K$-skyband}\index{$K$-skyband} query, introduced by
\citet{Papadias2005}, is a simlar concept as skyline stratum. A
$K$-skyband query reports all tuples which are dominated by at most
$K$ points.

\fixme{It is easy to see, that the following identities hold}{thats wrong}
        x3
  x1  
 
    x2

x1, x2 are in stratum 1, x3 is in stratum 1 but while x1 and x2 are in
0-skyband, x3 is not is 1-skyband because it is dominiated by x1 and
x2 so it is in 2-skyband. Hence no general relation can be established
between K-skyband and skyline stratum.

The skyband rank of a point $p$ can be computed by counting the points
in the anti-dominace region of $p$.

\begin{eqnarray}
\skyband_C^0(\relation{R}) &=& \skyline_C^1(\relation{R}) \label{equ:skyband} \\
\skyband_C^n(\relation{R}) &\not=& \bigunion_{1 \le i \le n+1} \skyline_C^i(\relation{R}) \quad \textnormal{for}\ n \ge 0\label{equ:skybandgeneral} \\
\skyline_C^n(\relation{R}) &\not=& \skyband_C^{n+1}(\relation{R}) \difference \skyband_C^n(\relation{R}) \quad \textnormal{for}\ n \ge 1
\end{eqnarray}

The branch-and-bound-skyline (BBS) \citep{Papadias2005} supports the
computation of $K$-skyband queries, as stated by \citet{Papadias2005},
BNL and SFS can compute $K$-skybands, this can be easly done by
maintaining a the number of tuples that dominate a tuple in the tuple
window. Increase the number by one each time a tuple in the tuple
window is dominated by the current tuple and once this count is
greater than $K$ drop the tuple from the tuple window.


An interessing combination of \inlinesql{SKYLINE OF} and
\inlinesql{TOP $k$} is given by the
\emph{top-$k$-skyline}\index{top-k-skyline} operator
\todo{\citep{Brando2007, Goncalves2005a, Goncalves2005}}{check
citation}, where as many skyline startum are computed till at least
$k$ tuples are found, or the entire relation is returned.


\subsection{Monoton vs. linear scoring functions}\label{subsec:scoring}
see \citep{Chomicki2002a} page 5, Theorem 4

from \citep{Borzsonyi2001}: One of the nice properties of the Skyline
of a set $\mathcal{M}$ is that for any monotone scoring function
$\mathcal{M} \rightarrow \mathbb{R}$, if $p \in \mathcal{M}$ maximizes
that scoring function, then $p$ is in the Skyline.  In other words, no
matter how you weight your personal preferences towards price and
distance of hotles, you will find your favorite hotl in the Skyline.
In addition, for every point $op$ in the Skyline, there exists a
monotone scoring function such that $p$ maximizes that scoring
function.  In other words, the Skyline does not contain any hotels
which are nobody's favorite.

\subsection{\inlinesql{SKYLINE OF DISTINCT} is \emph{not} expressible in SQL}
\todo{proof it}{}

\subsection{Classification of Skyline Algorithms}

\todo{\citet{Kossmann2002} suggested a set of criteria for evaluating skyline algorithms:}{rephrase}

\begin{enumerate}
\item \emph{Progressiveness}: the first results should be reported to the user almost instantly and the output size should gradually increase.

\item \emph{Absence of false misses}: given enough time, the algorithm should generate the entire skyline.

\item \emph{Absence of false hits}: the algorithm should not discover temporary skyline points that will be later replaced.

\item \emph{Fairness}: the algorithm should not favor points that are particularly good in one dimension.

\item \emph{Incorporation of preferences}: the users should be able to determine the order according to which skyline points are reported.

\item \emph{Universality}: the algorithm should be applicable to any dataset distribution and dimensionality, using some standard index structure.
\end{enumerate}

\section{Related Problems}
Convex hull, \emph{top-K} queries, and nearest-neighbor search
(especially in the context of spacial skylines ``give me the next good
restaurant'')

In particlar, the convex hull contains the subset of skyline points
that may be optimal only for linear preference functions (as opposed
to any monotone function).\todo{from \citep{Papadias2005}}{rephrase}



%%
%% CHAPTER: Related Works
%%



\chapter{Related Works}
\label{chap:relatedworks}
\todo{}{}
Since the introduction of the skyline operator \cite{Borzsonyi2001}, a
number of secondary-memory algorithms have been developed for
efficient skyline computation. These algorithms can be classified into
two categories. The first one involves solutions that do not require
any preprocessing on the underlying dataset. Algorithms such as
{\em Block Nested Loops} (BNL) \cite{Borzsonyi2001}, 
{\em Divide and Conquer} (D\&C) \cite{Borzsonyi2001}, 
{\em Sort First Skyline} (SFS) \cite{Chomicki2003}, and
{\em Linear Elimination Sort for Skyline} (LESS) \cite{Godfrey2005}
belong to this category.
The algorithms in the second category utilize different index structures
such as sorted lists and R-trees to reduce the query costs.
Well-known algorithms in this category include 
{\em Bitmap} \cite{Tan2001}, 
{\em Index} \cite{Tan2001},
{\em Nearest Neighbor} (NN) \cite{Kossmann2002}, and
{\em Branch and Bound} (BBS) \cite{Papadias2003, Papadias2005}.

The advantage of index-based algorithms is that they need to access
only a portion of the dataset to compute the skyline, while
non-index-based algorithms have to visit the whole dataset at least
once.  However, index-based algorithms have to incur additional time
and space costs for building and maintaining the indexes.  Comparisons
of these methods are presented in several works
\cite{Tan2001, Kossmann2002, Chomicki2003}.

\section{Main Memory Only Skyline Algorithms}
\todo{}{}

\section{Non-indexed based Skyline Algorithms}
The skyline algorithms we have implemented are: BNL, SFS,
BNL+EF and SFS+EF. EF stands for {\em Elimination Filter},
which was introduced in \cite{Godfrey2005} as an essential 
routine for the LESS algorithm. 

\subsection{Block Nested Loops (BNL)}
BNL was implemented according to the algorithm proposed in \cite{Borzsonyi2001}.
A {\em tuple window} is maintained in the main memory for storing
the potential skyline tuples. Once the window becomes full,
an overflow file has to be generated.
In the PostgreSQL execution engine, the BNL operator 
lies in the iterator tree between the \texttt{ORDER BY} 
and the \texttt{GROUP BY} node (see Figure~\ref{fig:qp-agg-bnl-sort}),
to directly reflect the intended semantic of the \texttt{SKYLINE OF}-extension
to the SQL syntax.

% NOTE: it is actually between HAVING and ORDER BY, but HAVING is done 
% more or less in the GROUP BY, as the WHERE clause to some
% extend is directly used in the SeqScan/IndexScan node



\begin{table}[htbp]
\centering
\begin{tabular}{cp{100mm}}
Symbol & Description \\
\hline
$\mathcal{I}$ & input for skyline computation (\emph{type}: set of $d$-dimensional points) \\
$\mathcal{O}$ & output of skyline computation (\emph{type}: set of $d$-dimensional points) \\
$\mathcal{T}$ & temporary file (\emph{type}: set of $d$-dimensional points) \\
$\mathbb{W}$ & tuple window in main memory (\emph{type}: set of $d$-dimensional points with a timestamp value for each point) \\
% TODO: add a rank for the tuple window?
$p \dominates q$ & point $p$ dominates point $q$
\end{tabular}
\caption{Symbols used throughout the pseudo code}
\label{tab:pseudocodesymboles}
\end{table}



\begin{figure}[htbp]
\begin{lstlisting}[language=pseudo]
function SkylineBNL($\mathcal{I}$)
begin
	// initialization
	$\mathcal{O} \gets \emptyset$; $\mathcal{T} \gets \emptyset$; $\mathbb{W} \gets \emptyset$; $timestampIn \gets 0$; $timestampOut \gets 0$;

outer:
	while $\neg$EOF($\mathcal{I}$) do begin
		// propagate points that have been compared to all
		foreach $q \in \mathbb{W}$ do
			if $q_{timestamp}$=$timestampIn$ then begin
				append($\mathcal{O}$, $q$);
				release($\mathbb{W}$, $q$);
			end

		// fetch the next point
		$p \gets$ next($\mathcal{I}$);
		$p_{timestamp} \gets timestampOut$;
		$timestampIn \gets timestampIn + 1$;

		// compare $p$ to all points in the tuple window $\mathbb{W}$
		foreach $q \in \mathbb{W}$ do begin
			if $q \dominates p$ then begin
				free($p$);
				continue outer;
			end
			else if $p \dominates q$ then
				release($\mathbb{W}$, $q$);
		end

		// note: $p$ is skyline candidate
		if hasfreespace($\mathbb{W}$) then
			// add $p$ to the tuple window $\mathbb{W}$
			add($\mathbb{W}$, $p$);
		else begin
			// write $p$ to the tempfile $\mathcal{T}$
			append($\mathcal{T}$, $p$);
			free($p$);
			$timestampOut \gets timestampOut + 1$;
		end

		// continue with next run if necassary
		if EOF($\mathcal{I}$) then begin
			// switch to tempfile $\mathcal{T}$
			$\mathcal{I} \gets \mathcal{T}$; $\mathcal{T} \gets \emptyset$;
			$timestampIn \gets 0$; $timestampOut \gets 0$;
		end
	end

	// flushing the tuple window
	foreach $q \in \mathbb{W}$ do begin
		append($\mathcal{O}$, $q$);
		release($\mathbb{W}$, $q$);
	end

	return ($\mathcal{O}$);
end
\end{lstlisting}
\caption{Pseudo code for Block-Nested-Loops (BNL) Algorithm}
\label{code:bnl}
\end{figure}


\subsection{Sort First Skyline (SFS)}
The implementation of SFS is according to \cite{Chomicki2003}. 
It differs from BNL in that the data is topologically sorted at start-up time.
We realize the sorting by utilizing the same physical operator as for 
the \texttt{ORDER BY}-clause.
%
In the presence of a suitable index, an explicit sort phase can be
omitted.
%The skyline operator can make use of more indexes than the \texttt{ORDER BY}-clause,
%since the semantic of the skyline operator is insensitive to the order of attributes.
While 
%the \texttt{ORDER BY}-clause requires that the order of the
%fields, and direction (\texttt{ASC}/\texttt{DESC}) of the index match
%the \texttt{ORDER BY}-clause, 
the skyline operator is insensitive to
the order of attributes, more indexes can be considered by the
query optimizer for the access path selection.  We modified the query
optimizer accordingly.


\begin{figure}[htbp]
\begin{lstlisting}

\end{lstlisting}
\caption{Pseudo code for Sort-First-Skyline (SFS) Algorithm}
\label{code:sfs}
\end{figure}


\subsection{Linear Elimination Sort for Skyline (LESS)}
\todo{}{}
\subsubsection{Elimination Filter (EF)}

\subsection{SFS+EF (move to Implementation)}
In \cite{Godfrey2005} Godfrey et al. proposed the LESS
algorithm, which is an improvement of SFS due to the introduction of
the concept of {\em elimination filter} (EF). With the original LESS
algorithm the elimination filtering is carried out in the pass zero of
the external sort routine to eliminate records quickly.

In our case, in order to integrate the elimination filter into the SFS algorithm,
while at the same time preserving the utilization of the  
physical sort operator, 
we implemented the elimination filter {\em before} the sort routine.
Speaking in terms of the iterator tree, the EF node is a child of the sort node,
which in turn is a child of the SFS node (see Figure~\ref{fig:qp-sfs-ef}).
Furthermore, we do not integrate the skyline computation into the final pass 
of the merge sort phase, as described in \cite{Godfrey2005}.
Therefore, technically speaking, SFS+EF is not an equivalent implementation of LESS.
However, the elimination filter is preserved in SFS+EF,
which is essentially the gist of LESS.

The implementation of EF is similar to BNL.
An elimination filter window is maintained in the main memory.
We use 8 KB as default window size.
The difference between EF and BNL is that EF does not write tuples to a
temporary file if the tuple window is full, and that the relative order of tuples 
going through the EF is preserved.

\subsection{BNL+EF (move to Implementation)}
Inspired from the idea of the elimination filter in LESS, we experimented
a new combination of BNL and EF. That is, the elimination filter 
is executed before the BNL algorithm. Since our implementation of the
elimination filter is independent from the external sort routine,
the coding of this variant is straightforward.
It turns out that the algorithm BNL+EF is a substantial improvement
to BNL.

\subsection{Divide and Conquer (D\&C)}
\todo{}{}

\subsection{TODO}
We experimented with four window policies for both the tuple
window (applied for BNL and SFS) and the EF window (for elimination filter): 
\emph{append}, \emph{prepend}, \emph{entropy} and \emph{random} \cite{Godfrey2007}.
We implemented both windows with doubly linked lists with a sentinel, thus
the time cost for insertion and deletion was in $O(1)$.
Furthermore, as the insert 
position for the \emph{entropy} and \emph{random} window policy was determined while iterating 
over the tuple window, the insert operation was also in $O(1)$.

If the EF window is full, in case of EF window policy 
\emph{entropy} or \emph{random}, the tuple with the lowest ranking is 
evicted to make space for a higher ranked tuple. 
Instead of calculating the entropy, a random value is used for ranking by
the window policy \emph{random}.
With EF window 
policy \emph{append} and \emph{prepend}, once the EF window is full, space
in the EF window is only gained if a tuple in the EF window is dominated by
the incoming tuple and thus removed.
In our implementation the window policy \emph{entropy} can only be used if 
statistics for basetables is available.

In summary, we conducted experiments of the four skyline algorithms:
BNL, SFS, BNL+EF, SFS+EF, upon each of which four 
window policies were applied: \emph{append}, \emph{prepend}, \emph{entropy} and \emph{random}.
For BNL+EF and SFS+EF, we applied on both windows
the same window policy in our experiments.

\section{Indexed based Skyline Algortihms}
\todo{}{}

\subsection{Bitmap}
\citep{Tan2001}
\todo{}{}

\subsection{Index}
\citep{Tan2001}
\todo{}{}

\subsection{Nearest Neighbor (NN)}
\citep{Kossmann2002}
\todo{}{}

\subsection{Branch and Bound (BBS)}
\citep{Papadias2003, Papadias2005}
\todo{}{}

\section{Continous Skyline Computation}
This is a whole other class of skyline algorithms, the task is here
the initialy compute the skyline and that update the skyline of tuples
are added or removed from the dataset, e.g. in a streaming scenario.
\todo{}{}



%%
%% CHAPTER: Implementation
%%



\chapter{Implementation}
\section{SQL Extension}

\citet{Borzsonyi2001} proposed the following extension to the SQL's \inlinesql{SELECT} statement with an optional \inlinesql{SKYLINE OF}-clause:
\begin{sql}
SELECT ... FROM ... WHERE ... \\
GROUP BY ... HAVING ...       \\
SKYLINE OF \textnormal{[}DISTINCT\textnormal{]} $a_1$ \textnormal{[}MIN$|$MAX$|$DIFF\textnormal{]}, ..., $a_m$ \textnormal{[}MIN$|$MAX$|$DIFF\textnormal{]} \\
ORDER BY ...
\end{sql}

In addition, we extended the standard syntax to specify
\begin{itemize}
\item The treatment of NULL values (\texttt{NULLS FIRST} and \texttt{NULLS LAST})
\item The usage of order relations other than $<$ and $>$ (\texttt{USING \emph{Op}})
\item Operational aspects of skyline computation, such as 
\begin{itemize}
\item \emph{method} (BNL, SFS, MNL, PRESORT (2 dim only))
\item \emph{tuple window size} in terms of memory and/or number of slots
\item \emph{tuple window policy} (append, prepend, ranked by entropy, ranked by a random value)
\item \emph{usage of indexes} (\texttt{NOINDEX})
\item \emph{usage of elimination filter (EF), 
  	with the possiblity to influence the EF window in the same way
  	as for the BNL or SFS node}
\end{itemize}
\end{itemize}

\subsection{Syntax (Railroad Diagrams)}
To describe the formal grammar of the \inlinesql{SKYLINE OF}-clause
extension to the SQL query syntax we use syntax diagrams (or railroad
diagrams).  Railroad diagrams are a graphical alternative to
Backus-Naur form or EBNF and they have been made popular by books such
as the ``Pascal User Manual'' written by Niklaus Wirth.  Nowadays
railroad diagrams are used in user manuals such as the ``Oracle
Database SQL Reference'' (see \citep[Oracle2005]).  We believe the
general concept of railroad diagrams is easy to grasp and does not
need a further explanation at this point, so we can directly focus on
our \inlinesql{SKYLINE OF} extension.

\railoptions{ah}
\railalias{selectclause}{select\_clause}
\railalias{targetlist}{target\_list}
\railalias{intoclause}{into\_clause}
\railalias{fromclause}{from\_clause}
\railalias{whereclause}{where\_clause}
\railalias{groupclause}{group\_clause}
\railalias{havingclause}{having\_clause}
\railalias{skylineclause}{skyline\_clause}
\railalias{sortclause}{sort\_clause}
\railalias{selectlimit}{select\_limit}
\railalias{qualOp}{qual\_Op}
\railalias{skylineofexpr}{skyline\_of\_expr}
\railalias{skylineoptions}{skyline\_options}
\railalias{cexpr}{c\_expr}


% \railparam{\thinline}
% \railparam{\thicklines}
\railnontermfont{\rmfamily\itshape}
\railtermfont{\ttfamily\upshape\small}
\railboxheight 12pt
\railinit

The following diagram depicts how the \inlinesql{SKLINE OF}-clause
(denoted by \nt{skyline\_clause} in the diagram) fits into an SQL
select query.  It is right between the optional \inlinesql{GROUP
BY}/\inlinesql{HAVING}-clause and the optional \inlinesql{ORDER
BY}-clause, denoted by \nt{group\_clause} / \nt{having\_clause} and
\nt{sort\_clause}. We omit some details here but it should be clear
from the context that \nt{target\_list}, \nt{into\_clause},
\nt{from\_clause}, \nt{where\_clause}, \nt{group\_clause},
\nt{having\_clause}, \nt{sort\_clause}, and \nt{select\_limit} have
there usual meaning. We refer you to the according SQL standard and
especially to the PostgreSQL documentation on SQL
\postgresdocu{sql-select.html}{SELECT}. For the non-terminals that we omitted
here we selected the same name as in the implemenation (see
\srcref{src/backend/parser/gram.y}), in order to easily find the exact definition.

%
\begin{rail}
selectclause :
    'SELECT' 'DISTINCT'? targetlist intoclause ? fromclause \\ 
    whereclause ? ( groupclause havingclause ? ) ? \\
    skylineclause ? sortclause ? selectlimit ? ';' ;
\end{rail}


The \nt{skyline\_clause} itself is preluded by keywords
\inlinesql{SKYLINE OF}, followed by an optional \inlinesql{DISTINCT}.
The essential part is the comma seperated list of
\nt{skyline\_of\_expr}, and it is closed by the optional 
\nt{skyline\_options} part. For the semantics of \inlinesql{DISTINCT}
see section~\ref{sec:distinct}. For the entire skyline clause we
introduced just a single new reserved keyword, see
section~\ref{sec:reservedkeywords}.

\begin{rail}
skylineclause : 
    'SKYLINE OF' 'DISTINCT' ? ( skylineofexpr + ',' ) skylineoptions ?;
\end{rail}

A \nt{skyline\_of\_expr} specifies how to treat a single dimension
of a skyline query. This includes the specification of the column
or even an expression (\nt{c\_expr}) and the specification of
\inlinesql{MIN}, \inlinesql{MAX}, \inlinesql{DIFF}, and 
\inlinesql{USING}~\emph{qualOP}. We call the later specification 
\emph{skyline direction} or just \emph{direction} for short, this
is because a similar concept (\inlinesql{ASC}/\inlinesql{DESC}) in the
\inlinesql{ORDER~BY}-clause is also called direction.  Furthermore the
treatment of null values can be specified using \inlinesql{NULLS
FIRST} and \inlinesql{NULLS LAST}.  We have to same concept for the
\inlinesql{ORDER BY}-clause, where this special treatment of null values 
was introduced in PostgreSQL 8.3.0 (see
\postgresdocu{sql-select.html\#SQL-ORDERBY}{SQL SELECT/ORDER BY}. For
the sementics of this see Section~\ref{sec:nullvalues}.

The indroduction of \inlinesql{USING}~\emph{qualOp} to skyline queries
is our idea, but as for the treatment of null values it was inspired
by a PostgreSQL extension to \inlinesql{ORDER~BY}-clause. See
section~\ref{sec:using-qualop} for more details.

In the \nt{target\_list} of the \nt{select\_clause} and in many other
places \nt{a\_expr} is used. This is the concept of a general expression
and the heart of the expression syntax. In certain places \nt{b\_expr}
is used, which is a restricted subset to avoid shift/reduce conflicts.

\nt{c\_expr} contains all the productions that are common to \nt{a\_expr}
and \nt{b\_expr} it is factored out to eliminate redundant coding, but
in our case we use it directly to avoid shift/reduce conflicts. Please
note that \texttt{'('} \nt{a\_expr} \texttt{')'} is a \nt{c\_expr}, so
an unrestricted expression can always be used by surrounding it with
parens. Furthermore \nt{c\_expr} contains to most common case a column
reference (\nt{columnref}) anyway and also function calls can be used
without an extra pair of paranthesis.

\begin{rail}
skylineofexpr:
    cexpr ( 'MIN' | 'MAX' | 'DIFF' | 'USING' qualOp )
    (() | 'NULLS FIRST' | 'NULLS LAST') ;
\end{rail}

The syntax we have described so far deals only with specifing the
skyline query itself and the ultimate goal of our work is building a
skyline query optimizer to automatically generate a good query plan
w.r.t. I/O, time, and memory consumption and decide all operational
aspects of the query evaluation.  It is well known that the cost
estimation of the skyline queries is a non-trivial task
\cite{Chaudhuri2006} since the performance of a skyline query is
sensitive to a number of parameters \cite{Godfrey2007}.

To be able to study different query plans, differnt physical
operators, and various options for the physical operators we
indroduced a set of options. This options list is preluded by the
keyword \inlinesql{WITH}.

Except from order of the tuples in the output all of the following
options do not have an impact on the result of the skyline
computation. Using either BNL or SFS will change to order of tuples in
the output, as SFS does a sort prior to skyline
computation. Furthermore the size of the tuple window and the tuple
window policy have an impact on the order of tuples. And even the
elimination filter and its tuple window size have an impact on the
output order, as a different amount of potential skyline tuples reach
the final skyline computation node, altough the elemination filter
does not change the relative order.  See detailed discution on
relative tuple order preserving property in
section~\label{sec:relative-tuple-order}.  To work around this
reordering if decired, sort the query result by means of an
appropriate
\inlinesql{ORDER~BY}-clause.  We did so in regression testing, we
ordered on the unique \inlinesql{ID} column, no matter what method and
what options used the results are or at least should be the
same. While the latter clearly indicates a flaw in the implemenation.

The options fall into three groups: elimination filter
(\inlinesql{EF}), physical operator (\inlinesql{BNL}, \inlinesql{SFS},
etc.), and access path selection (\inlinesql{NOINDEX}) and associated
options if applicable.

To tell the query planner to include a elimination filter (EF) in the
query plan specify the option \inlinesql{EF}.  If the
\nt{efwindowoptios} are omitted, the query planner uses the defaults
and plans the elimination filter with a 8~KB tuple window and the
tuple window policy \inlinesql{APPEND}. The 8~KB tuple window size
stem from PostgreSQL page size \texttt{BLCKSZ}, which is 8~KB on most
platforms.

The next group of options is to specify the main algorithm used for
skyline computation.
%
Currently the work horses of our skyline operator implementation into
PostgreSQL are the BNL and the SFS algorithm. BNL is the catch all
default in the query optimizer, only if a suitable index access path
is available SFS is selected. This automatic can be overruled by
specifing \inlinesql{BNL} or \inlinesql{SFS} as an option. Furthermore
the size and the tuple placement policy for the tuple window used by
BNL or SFS can be specified with the \nt{windowoptions}, see below.
In fact the options for the tuple window could be specified, while
leaving the decision which physical operator to take to the query
optimizer, but nevertheless these \nt{windowoptions} only have an
effect on BNL and SFS. See section~\ref{sec:operatorselection} for
more details on how the physical operator is selected.


The \inlinesql{PRESORT} method is more or less a special case of SFS,
which only works in the 2 dimensional case it was pointed out by 
\citet{Borzsonyi2001}. In the 2 dimensional case once the data
are ordered according to the two skyline expressions a single tuple is
enough to compute the skyline. See section~\ref{sec:presort}.

\inlinesql{MNL} stands for \emph{materialized nested loop}, which
is our own very basic and experipental nevertheless full general
skyline computation algorithm, i.e. skylines of any dimensionality,
distinct and non-distinct with the same type of expressions and
directions (\inlinesql{MIN}, \inlinesql{MAX}, $\ldots$) can be
computed. The approach is very simple: materialize all tuples from the
outer query plan node in a tuple store and compare one tuple after the
other agains all other tuples in the tuple store. It is obvious that
this algorithm has $O(n^2)$ run time complexity and very poor I/O
behaviour. Nevertheless it was easy to implement and gave us something
to play with while implementing other parts of the system and of
course for regression testing, because this method was just easier to
get right and later on use it to verify the results from other
algorithms. See section~\ref{sec:mnl}.

Two other special methods do exist, namely \texttt{1DIM} and
\texttt{1DIMDISTINCT}, as the names suggest they are only for the 1
dimensional non-distinct and distinct case.  These methods are
directly selected by the query planner and no options can be set for
them.  The tuplestore used by the method \texttt{1DIM} uses the
default \texttt{work\_mem} setting. See
section~\ref{sec:onedim-nondistinct} and
section~\ref{sec:onedim-distinct}.

We modified the query optimizer to decided in a cost based way to use
a \texttt{IndexScan} instead of a \texttt{SeqScan}, in case a suitable
index is present.  With \inlinesql{NOINDEX} option we enforce in the
query planner to not use a \texttt{IndexScan}, this is especially of
interest when profiling SFS, as SFS does a sort prior to skyline
computation.

\begin{rail}
skylineoptions : 
    'WITH' 
    ( 'EF' efwindowoptions ?) ? \\
    ( ( ( () | 'BNL' | 'SFS' ) windowoptions ? ) | 'MNL' | 'PRESORT' ) ? \\
    ( 'NOINDEX' ) ? ;
\end{rail}

The options for the elimination filter (EF) tuple window
\nt{efwindowoptions} are modulo renaming the same as for the tuple window
use by BNL and SFS cf. \nt{windowoptions} below.

\begin{rail}
efwindowoptions : 
    ( 'EFSLOTS' '=' slots) ? \\
    ( ( 'EFWINDOW' | 'EFWINDOWSIZE' ) '=' windowsize ) ? \\
    ( 'EFWINDOWPOLICY' '=' windowpolicy ) ? ;
\end{rail}

BNL and SFS are using a tuple window to do their job. Our
implementation allows to specify the size and the tuple placement
policy. The size can be defined in two differnt terms, either
in the number of slots or in the amount of RAM (in KB). When placing
a tuple into the tuple window it takes up exactly one slot and
as much RAM as required for the chunk of memory allocated with PostgreSQL
\texttt{palloc}. If both are given, i.e. \inlinesql{SLOTS} and \inlinesql{WINDOWSIZE}
the tuple window is only limited in the number of available slots and
the RAM constraints are ignored. When the \inlinesql{WINDOWSIZE}
option is used an accoring amount of RAM is used for the tuplewindow.
\inlinesql{WINDOW} is just an alias for \inlinesql{WINDOWSIZE}.  If
neither \inlinesql{SLOTS} nor \inlinesql{WINDOWSIZE} is given the
configuration variable \texttt{work\_mem} is used, which is 1~MB per
default. The other property which can be influenced is the order in which
tuples are placed in the tuple window, where the default is \inlinesql{APPEND}.

\begin{rail}
windowoptions : 
    ( 'SLOTS' '=' slots ) ? \\
    ( ( 'WINDOW' | 'WINDOWSIZE' ) '=' windowsize ) ? \\ 
    ( 'WINDOWPOLICY' '=' windowpolicy ) ? ;
\end{rail}

As indicated above a tuple window is used by the elimenation filter
(EF) and the BNL and SFS algorithm. For each of them the order in
which tuples are placed into the window is set by this option, where
the default is \inlinesql{APPEND}. See
section~\ref{sec:tuplewindowpolicies} for details.

\begin{rail}
windowpolicy : 'APPEND' | 'PREPEND' | 'ENTROPY' | 'RANDOM' ;
\end{rail}

At this point we would like to give a little example how the options can be
used (we slightly reformatted the output to make it fit into the page with
constraint):

\begin{interactive}
\sqlprompt{EXPLAIN ANALZYE} \rcomment{see the query plan and execution statistics}
\sqlpromptcont{SELECT * FROM a15d1e5s0idx} \rcomment{note: on relation ad1e50idx an index is defined}
\sqlpromptcont{SKYLINE OF d1 min, d2 min, d3 min} \rcomment{we do a 3 dim skyline query}
\sqlpromptcont{WITH} \rcomment{options for \inlinesql{SKYLINE OF} follow}
\sqlpromptcont{  EF} \rcomment{use an elimination filter (EF)}
\sqlpromptcont{    EFWINDOWSIZE=16} \rcomment{use 16 KB RAM and policy \inlinesql{ENTROPY} for EF}
\sqlpromptcont{    EFWINDOWPOLICY=ENTROPY}
\sqlpromptcont{  SFS} \rcomment{use SFS}
\sqlpromptcont{    WINDOWSIZE=512} \rcomment{use 515 KB RAM and policy \inlinesql{PREPEND} for SFS}
\sqlpromptcont{    WINDOWPOLICY=PREPEND}
\sqlpromptcont{  NOINDEX;} \rcomment{do not use an available index access path}

                                     QUERY PLAN
-----------------------------------------------------------------------------------
 Skyline  (cost=25106.90..25107.06 rows=9 width=124) \rcomment{estimated} 
     (actual time=329.052..342.313 rows=196 loops=1) \rcomment{actual}
   Skyline Attr: d1, d2, d3
   Skyline Method: sfs 3 dim \rcomment{3 dim and SFS}
   Skyline Stats: passes=1 rows=1303 \rcomment{some stats on the SFS node}
   Skyline Window: size=512k policy=prepend \rcomment{as requested}
   Skyline Cmps: tuples=25953 fields=62229 \rcomment{# of comparisons}
   ->  Sort  (cost=25104.70..25104.86 rows=66 width=124) 
           (actual time=329.046..329.564 rows=1303 loops=1)
         Sort Key: d1, d2, d3
         Sort Method:  quicksort  Memory: 368kB
         ->  Elimination Filter  (cost=24852.69..25102.69 rows=66 width=124) 
                 (actual time=0.088..325.329 rows=1303 loops=1)
               Elim Filter Attr: d1, d2, d3
               Elim Filter Method: elimfilter 3 dim
               Elim Filter Stats: passes=1 rows=
               Elim Filter Window: size=16k policy=entropy \rcomment{as requested}
               Elim Filter Cmps: tuples=313895 fields=828555
               ->  Seq Scan on a15d1e5s0  (cost=0.00..2924.00 rows=100000 width=124) 
                       (actual time=0.043..71.488 rows=100000 loops=1)
\rcomment{the effect of \inlinesql{NOINDEX} can be seen here as no \texttt{IndexScan} is used}
 Total runtime: 343.200 ms
(17 rows)
\end{interactive}

The reader might noticed that the grammar for \nt{skyline\_options}
contains a rather big amount of $\varepsilon$-productions and that this
grammar whould be easy to implement without any shift/reduce conflicts
using yacc/bison. In fact we defined the grammar for
\nt{skyline\_options}, just as simple as that:

\begin{rail}
skylineoptions:
    'WITH' ( () | ( name ( '=' value ) ? ) + )
\end{rail}

While the definition given above describes exactly the indented
sementics this definition gave as maximum flexibility during
development. Using the short definition above we were able to
introduce new options as we liked on the fly.  The options are passed
around from the parser, trought query planing to the execution engine
as a simple \emph{name/value} list.  So when ever we needed a new
option we just had to query this list at the desired point in the
code. If the equal sign and the value are omitted, this has the
semantics of assigning the integer const 1 to the name.

To tell the whole truth the grammar for \nt{select\_clause} is defined
a little bit different\footnote{see \srcref{src/backend/parser/gram.y}
for details} but only in the aspect of the assozitivity of the entire
\inlinesql{SKLYINE OF} clause, this is because the SQL:1992 Standard
\citep{SQL92} requires the following statement:

\begin{sql}SELECT foo UNION SELECT bar ORDER BY baz\end{sql}
to be parsed as
\begin{sql}(SELECT foo UNION SELECT bar) ORDER BY baz\end{sql}
and not as
\begin{sql}SELECT foo UNION (SELECT bar ORDER BY baz)\end{sql}

\noindent{}For the \inlinesql{SKYLINE OF} clause we decided that the it should be left
assoziative, i.e. 
\begin{sql}SELECT * FROM foo UNION SELECT * FROM bar SKYLINE OF baz\end{sql}
will be parsed as 
\begin{sql}SELECT * FROM foo UNION (SELECT * FROM bar SKYLINE OF baz)\end{sql}

\noindent{}We did so, because we believe the \inlinesql{SKYLINE OF} clause is closer
related to the \inlinesql{GROUP BY} clause than to the \inlinesql{ORDER BY}
clause, therefore we parse it in the same way.

\subsection{Reserved Keywords}
\label{sec:reservedkeywords}
On the lexicalical level we introduced one new \emph{reserved
keyword}: ``\inlinesql{SKYLINE}''\footnote{see
\srcref{src/backend/parser/keywords.c}}. Introducing a reserved
keyword has the usual consequences: it can not be used as normal
identifier, like illustrated in the following example:

\begin{interactive}
\sqlprompt{CREATE DATABASE SKYLINE;}
ERROR:  syntax error at or near "SKYLINE"
LINE 1: CREATE DATABASE SKYLINE;
                        ^
\end{interactive}
\noindent
Nevertheless the solution is easy and the same for every reserved
word, just quote it:
\begin{interactive}
\sqlprompt{CREATE DATABASE "SKYLINE";}
\end{interactive}

We did not define \inlinesql{MIN}, \inlinesql{MAX}, and
\inlinesql{DIFF} as reserved keywords, because the SQL aggregate
functions \inlinesql{MIN} and \inlinesql{MAX} are implemented as
functions and are looked up at runtime and not directly hardcoded into
the grammar. Defining these keywords as reserved keywords would mess
up the implementation of SQL aggregate functions.

\section{Semantics}

\subsection{\inlinesql{DISTINCT} and non-\inlinesql{DISTINCT}}
\label{sec:distinct}
\todo{}{}

\subsection{One dimensional \inlinesql{SKYLINE OF} is different to SQL \inlinesql{MIN}/\inlinesql{MAX}}
\todo{for 1 dim distinct use FIRST as supported by Microsoft SQL Server, PostgreSQL does not have this, but it could be built in}{}
\todo{for 1 dim distinct use subselect/self-join and limit 1}{}

skyline 1d min neq sql min:

sql min, max, distinct != skyline min, max, distinct

\todo{1 dim with out distinct can be emulated with a subselect or a self-join}{}

select d1 from a2d100 skyline distinct d1 min = select min(d1) from a2d100;


wenn mehr als ein column in der result list ist


\subsection{\inlinesql{USING}~\emph{qualOp}}
\label{sec:using-qualop}

\todo{lala}{}

\subsection{Skyline in the presents of NULL values}
\label{sec:nullvalues}
\begin{verbatim}
skyline by nulls first / nulls last

Hannes=# select * from foo skyline by (price) nulls first;

 id | price | dist
----+-------+------
  5 |       |    3

Hannes=# select * from foo skyline by distinct (price) max;

 id | price | dist
----+-------+------
  5 |       |    3
(1 row)

Hannes=# select * from foo skyline by distinct (price) max nulls last;

 id | price | dist
----+-------+------
  1 |    10 |    1

should in case of max nulls last be the default? on sorting it's not.
\end{verbatim}

\subsection{\inlinesql{SKYLINE OF} and \inlinesql{GROUP BY}}
\begin{verbatim}
skyline and group by

select year, count(*)
from logfile
group by year
skyline by month min;


select year, count(*)
from logfile
group by year
skyline by year min;

==>

select year, count(*), month
from logfile
group by year, month
skyline by month min

hm? i.e. the skyline expr has to be added to the group by.
the result might be a bit unexpected if the skyline expr
is not part of the result nor of the group by clause


01 2000
02 2000
01 2001
01 2001

select year, count(*) from logfile group by year

2000 2
2001 2


select year, count(*), month from logfile group by year, month


2000 1 01
2000 1 02
2001 2 01

skyline by month min

2000 1 01
2001 2 01



skyline
  aggrate
     scan


Eder=# select id, count(*) from e2d100 group by id skyline by (d1) min;
ERROR:  column "e2d100.d1" must appear in the GROUP BY clause or be used in an aggregate function
\end{verbatim}

\subsection{\inlinesql{SKYLINE OF} is different to SQL:2003 \inlinesql{WINDOW} clause}

\todo{}{explain more}

\section{PostgreSQL Architecture}

Before we go into the details we would like to give a brief overview
of PostgreSQL architecture. According to \citep{Conway2006a} PostreSQL
has five main components:

\begin{enumerate}
\item \emph{parser / analyzer:\/} parse the query string
\item \emph{rewriter:\/} apply rewrite rules. SQL views work by means of this mechanism.
\item \emph{optimizer:\/} determine an efficient query plan
\item \emph{executor:\/} execute a query plan
\item \emph{utility processor:\/} process DDL statements like \inlinesql{CREATE TABLE}
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.75]{plots-qp/pgsql-arch}
\caption{Architecture Diagram. Lightblue blackground indicates the components we modified to support skyline queries.}%
\label{fig:pgsql-arch}%
\end{figure}

\todo{changeset: [140] \texttt{is\_simple\_subquery}, do not pull up subqueries with a skyline query}{}

\section{Parsing the Skyline Query}

\section{Query Analyzing}

\section{Query Planning}

\subsection{Selecting Indexes}

%It is well known fact that the skyline operator is insensitive to the order of attributes.
%To versatile all suitable access paths (indexes) we modified the query
%optimizer accordingly.


\subsection{Preserving relative tuple order}
\label{sec:relative-tuple-order}

see \texttt{skyline\_method\_preserves\_tuple\_order} in \srcref{src/backend/utils/skyline/skyline.c}

\subsection{Physical operator selection}
\label{sec:operatorselection}

\subsection{Using relation statistics}

PostgreSQL does not do a good job with statistics and subqueries.

\todo{PostgreSQL as of 8.3 does not derive the stats for subselect like \inlinesql{explain analyze select * from (select * from i15d1e6s0 limit 1000) as a skyline of d1 min, d2 min with windowpolicy=ranked;}}{}

\subsection{Cardinality and Cost Estimation}

cite \citep{Buchta1989}

\subsubsection{Tuple window size}
One could be tempted to set the tuple window size according to the
outcome of the cardinality estimation, but the assumtion that at no
time more than \texttt{output\_tuples} will be in the window does not
hold. To see this image the BNL algorithm running on a uniformly
distributed dataset, which implies the expected result set size is
$\Theta(\log(n)^{d-1} / (d-1)!)$ but the order of the tuple stream is
as such that before seeing the actual skyline tuples a lot of
anti-correlated tuples show up in the tuple stream.  The tuple window
will fill up with non skyline tuples.

We would like to also point out, that larger window and and less
passes do not always mean better runtime, as with larger windows the
number of comparisons per tuple could increase and therefore more CPU
time is required, so there is a break even point. For experimental
results see section~\ref{sec:analysis-window-size}.

\subsection{\inlinesql{LIMIT} / \inlinesql{TOP $k$}}
how top k interacts with skyline, no special measures have to be taken
as the upper node will stop fetching tuples. only in cost estimation.


\section{Query Execution}

The original System R prototype compiled query plans into machine
code, whereas other systems like INGRES, the grandfather of
PostgreSQL, generated an interpretable query plan. In the 1980 query
interpreation was considered a ``mistake'' by the INGRES
authors. Moore's law and enabling cross-platform portability, every
system now compiles queries into some kind of interpretable data
structure; the only difference across systems these days is the level
of abstraction \citep{Hellerstein2005}. We stick to the represenation
as a tree, as it is used by PostgreSQL (see Figure~\ref{fig:qp-agg-bnl-sort}).

\begin{figure}[htbp]
\centering
\subfloat[Query Plan]{\includegraphics[scale=0.5]{plots-qp/qp-agg-bnl-sort}}\\
\subfloat[Query]{%
\parbox{100mm}{%
\texttt{%
SELECT d.DeptName, AVG(e.Salary), AVG(e.Revenue)\\
FROM emp e JOIN dept d on (e.Dno = d.DeptId)\\
GROUP BY d.DeptName\\
SKYLINE OF AVG(e.Salary) MAX, AVG(e.Revenue) MIN\\
ORDER BY AVG(e.Salary) DESC
}
}
}%
\caption{Example query plan for BNL}%
\label{fig:qp-agg-bnl-sort}%
\end{figure}

%

\begin{figure}[htbp]
\subfloat[BNL+EF]{%
\begin{minipage}[b]{\onecolumnwidth}%
\centering%
\includegraphics[scale=0.5]{plots-qp/qp-bnl-ef}%
\label{fig:qp-bnl-ef}%
\end{minipage}%
}%
\hspace{\columnsep}%
%
\subfloat[SFS+EF]{%
\begin{minipage}[b]{\onecolumnwidth}%
\centering%
\includegraphics[scale=0.5]{plots-qp/qp-sfs-ef}%
\end{minipage}
\label{fig:qp-sfs-ef}%
}%
%
\\
%
\subfloat[SFS \emph{w/ index}]{%
\begin{minipage}[b]{\onecolumnwidth}%
\centering%
\includegraphics[scale=0.5]{plots-qp/qp-sfs-index}%
\label{fig:qp-sfs-index}%
\end{minipage}%
}%
\hspace{\columnsep}%
%
\subfloat[SFS+EF \emph{w/ index}]{%
\begin{minipage}[b]{\onecolumnwidth}%
\centering%
\includegraphics[scale=0.5]{plots-qp/qp-sfs-index-ef}%
\label{fig:qp-sfs-index-ef}%
\end{minipage}%
}%
\caption{Query plans for: 
\texttt{SELECT * FROM hotel SKYLINE OF price MIN, dist MIN;}}%
\end{figure}


\subsection{The iterator model in the executor}

\subsection{Special case: one dimensional}
\label{sec:onedim-nondistinct}
use is limited

\subsection{Special case: one dimensional with distinct}
\label{sec:onedim-distinct}

\subsection{Special case: two dimensional with presort}
\label{sec:presort}

in case a suitable access path, no sort is needed,

brauchbar, da es unserer vermutung nach ein ein gut anzuwendender fall
ist, aber d=2 macht skyline sinn.

\subsection{Na\"{\i}ve method: \emph{MNL: materialized nested loop}}
\label{sec:mnl}

\subsection{Tuple Window}

\todo{write about timestamp needed for BNL}{}

\subsubsection{Placement Policies}
\label{sec:tuplewindowpolicies}

\subsection{BNL}

\subsection{SFS}

\subsection{Elimination Filter (EF)}

\subsection{SFS+EF (a LESS Variant)}

\subsection{BNL+EF}

\section{Development}
\subsection{Debugging PostgreSQL}
During development it was very helpful to run the PostgreSQL backend
in \texttt{--single} mode. A single backend, enter the query directly,
edit \& continue in msvc.


\subsection{Regression Testing}
\todo{see \srcref{test/....}}{}
\todo{see more extensive see perl script}{}



%%
%% CHAPTER: Results
%%



\chapter{Results}
\label{chap:Results}


\section{Experimental Setup}
We ran our experiments on seven Dell OptiPlex 755, Intel Pentium
Dual-Core CPU E2160 (1.80GHz, 1MB L2 cache), with 1~GB RAM and Seagate
Barracuda 160~GB HDD (7200~rpm, SATA 3.0Gb/s, 8~MB cache) with a
single NTFS partition,
% average latency 4.16msec
running Microsoft Windows XP (SP2).
% 
Our implementation was based on PostgreSQL 8.3.0 and was compiled
using Microsoft Visual Studio 2005 (SP1) using the \texttt{RELEASE}
configuration with assertions disabled.
%
PostgreSQL was configured to use 200 MB of RAM for shared buffers,
with auto vacuuming disabled, and all other settings were left as
default.

If not otherwise mentioned, a tuple window size of 1024~KB (equal to
the PostgreSQL \texttt{work\_mem} setting), and an EF tuple window
size of 8~KB (equal to the PostgreSQL block size) were used.

The tables for the test runs have been generated using the extended
version \cite{Eder2007a} of the dataset generated presented in
\cite{Borzsonyi2001}, which allows to generate tables with
different initial seeds for the random generator. All experiments
were carried out on three different sets with varying initial seed, for each
distribution type (independent, correlated, and anti-correlated), and
with 100, 500, 1k, 5k, 10k, 50k, 100k tuples.

Each tuple consists of a unique 4 byte integer \emph{id} and 15
randomly generated 8 byte floats $d_1, \ldots, d_{15}$. With a 23 byte
tuple header and the alignment it sums up to a tuple length of 152 bytes. 
The memory chunk used by the PostgreSQL memory allocation function
(\texttt{palloc}) was 264 bytes long.
%The tuples are 152 bytes long, but the memory chunk used by PostgreSQL memory allocation function (palloc) is 264 bytes long.
%
%23 bytes tuple header, (0 bytes for null value bitmap) 
%
%data align at 8:
%4 (id) + 8 * 15 (d1-d15) = 124
%
%= 148 + alignment = 152
%
%MAXALIGN 
%MAXIMUM_ALIGNOF 8
%
%http://www.postgresql.org/docs/current/static/storage-page-layout.html

For the experiments using an index, a duplicate of the same set of
tables was used, including six indexes, where index $k$ is an index on
$d_1, \ldots, d_k$. This all sums up to 126 tables and an database of
approximately 1 GB.  
For most of our experiments we did not consider tables with more than
100k tuples, as the runtime for a 15 dimensional skyline query on 100k
tuples went up to 30 minutes.

% TODO hot cache, we ensure the table is in the shared buffer, before
% running the query, as each of the implemented methods has to read the
% entire table anyway

All experiments were carried out with a \emph{hot disk cache}, i.e. due to
appropriate queries all pages were in the shared buffers.


\subsection{Source Code}
Although we continously merging \texttt{CSV HEAD} of \fixme{PostgreSQL
source repository}{ref} into our main development branch, we decided
to base this paper on branch \texttt{REL8\_3\_STABLE}, in order to
have a more stable and reproducibly setting, i.e. all experiments in
this paper are based on version 8.3.0 of PostgreSQL with our patch for
the skyline operator applied.

\subsection{Lesson learned}
A lesson we have painfully learned during our experiments is to
minimize all possible influences on the runs to avoid skewed
results. This esspecially includes: screen savers, power saving or
standby options and any form of automatic software update suche as
Microsoft Windows Update or Google Pack software updater.

\subsection{Random Dataset Generator}

For our experiments we used a modified version \citep{Eder2007a} of
the popular dataset generator from \citep{Borzsonyi2001}.  Our
modified version can be used as command line utility or as a
PostgreSQL module. The PostgreSQL module provides a set returning
function and creates datasets on the fly.  The details are described
in the following sections.  But first of all we describe which type of
dataset are generated by the dataset generator.

\subsubsection{Independant, Correlated, and Anti-Correlated Datasets}
\label{sec:corr-anti-indep}

The main parameters one can vary for a generated dataset are
\emph{cardinality}, i.e. number of tuples, \emph{dimensionalty} and
the \emph{distribution type} and types are as of \citep{Borzsonyi2001}: 
\emph{independant}, \emph{correlated}, and \emph{anti-correlated}.

%Instead of giving a lenghty description of how the differnt
%distributions are generated, we present the essential parts of the
%source, as we believe this is the precisest way to describe it. Here
%are the some basic building blocks:

Before we give a detailed describtion of this distribution types, we
show some of the basic build blocks used for generating them, as we
believe the source code of the implementation is the precisest way to
describe it:

\begin{lstlisting}
static double
random_equal(double min, double max)
{
	double x = (double) rand() / RAND_MAX;
	return x * (max - min) + min;
}
\end{lstlisting}

As expected \lstinline{random_equal()} will return a random value $x
\in [\textnormal{min}, \textnormal{max}]$.

\begin{lstlisting}
static double
random_peak(double min, double max, int dim)
{
	int		d;
	double	sum = 0.0;

	for (d = 0; d < dim; d++)
		sum += random_equal(0, 1);
	sum /= dim;
	return sum * (max - min) + min;
}
\end{lstlisting}

The function \lstinline{random_peak()} returns a random value $x \in
[\textnormal{min}, \textnormal{max}]$ as sum of $\textnormal{dim}$
equally distributed random values.

\begin{lstlisting}
static double
random_normal(double med, double var)
{
	return random_peak(med - var, med + var, 12);
}
\end{lstlisting}

This function \lstinline{random_normal()} is our way to generate a
normally distributed value $x \in (\textnormal{med} -
\textnormal{var}, \textnormal{med} + \textnormal{var})$ with expected
value $E[x] = \textnormal{med}$.
%
This implementation is motivated through the central limit theorem and
based on the observation that a $12$-fold sum of $[0,1]$ uniformlly
distributed random value yields a sufficient good normally distributed
value. A prerequirement for this to work, is that the $12$ uniformlly
distributed values are intependent. While this can not be guaranteed
for \lstinline{random_equal()} we verified that data generated by
\lstinline{random_normal()} are sufficiently normally distributed with
the Shapiro-Wilk test.

Now we focus on the different distribution types and how they are
generated and we show some of their properties:

\begin{itemize}
\item \emph{indep}: 
for this type of dataset, all attribute values are generated
independently using a uniform distribution. Figure
\ref{fig:density-2d-i2d1e5} shows an density plot and statistics of
such an independent dataset with 100k tuples and $d = 2$. The skyline
tuples of this dataset are the lower left corners of the red line,
where the red line is the ``skyline''. The density of points within a
specific subregion is indicated by grayscale values, the darker the
more points are in the subregion. Above and to the right of the
grayscale density plot is the border distribution for each dimension,
in this plots the blue line indicates the density of a normal
distribution with the same mean and standard deviation as the border
distribution.

The implementation is as straight forward as expected:

\begin{lstlisting}
int		d;

for (d = 0; d < dim; d++)
	x[d] = random_equal(0, 1);
\end{lstlisting}

% TODO: place table and picture next to each other instead of below
\begin{figure}[htbp]
\centering
\sbox{\tempbox}{\includegraphics[width=100mm]{plots-density/density-2d-i2d1e5}}%
\subfloat[Density Plot]{\usebox{\tempbox}}%
\subfloat[Statistics]{%
\begin{minipage}[b]{38mm}%
\vbox to \ht\tempbox{%
\vfil
\begin{tabular}[b]{r|rr}%
	& d1 	& d2 \\
\hline
mean	& 0.500 & 0.500 \\
var	& 0.083 & 0.083 \\
\hline
cor	& d1	& d2 \\
\hline
d1	& 1.000 & 0.000 \\
d2	& 0.000 & 1.000 \\
\end{tabular}%
\vfil
}
\end{minipage}%
}%
\caption{Independent dataset (100k tuples)}%
\label{fig:density-2d-i2d1e5}%
\end{figure}

\item \emph{corr}: 
a correlated dataset represents an environment in which points which
are good in one dimension are also good in the other dimensions. 

%For instance, students which have a good publication record typically also
%do well in their preliminaries. 

A vextor $x$ with the dimension $dim$ is generated in the following way:

\begin{lstlisting}
do
{
	int		d;
	double	v = random_peak(0, 1, dim);
	double	l = v <= 0.5 ? v : 1.0 - v;
	
	for (d = 0; d < dim; d++)
		x[d] = v;

	for (d = 0; d < dim; d++)
	{
		double h = random_normal(0, l);
		x[d] += h;
		x[(d + 1) % dim] -= h;
	}
} while (!is_vector_ok(dim, x));
\end{lstlisting}

Due to the way it is computed an $x[d]$ could get out of the bound,
\lstinline{is_vector_ok()} verifies that all coordinates of $x$ are
within the interval $[0,1]$.

Figure \ref{fig:density-2d-c2d1e5} shows a correlated dataset with
100k tuples for $d = 2$.

\begin{figure}[htbp]
\centering
\sbox{\tempbox}{\includegraphics[width=100mm]{plots-density/density-2d-c2d1e5}}%
\subfloat[Density plot]{\usebox{\tempbox}}%
\subfloat[Statistics]{%
\begin{minipage}[b]{38mm}%
\vbox to \ht\tempbox{%
\vfil
\begin{tabular}[b]{r|rr}
	& d1 	& d2 \\
\hline
mean	& 0.500 & 0.500 \\
var	& 0.049 & 0.049 \\
\hline
cor	& d1	& d2 \\
\hline
d1	& 1.000 & 0.717 \\
d2	& 0.717 & 1.000 \\
\end{tabular}
\vfil
}
\end{minipage}
}
\caption{Correlated dataset (100k tuples)}%
\label{fig:density-2d-c2d1e5}%
\end{figure}


\item \emph{anti}:
an anti-correlated dataset represents an environment in which points
which are good in one dimension are bad in one or all of the other
dimensions. The standard example used in the skyline literature falls
into this category: hotels are either cheap and far away from the
beach or expensive and close to the beach.

\begin{lstlisting}
do
{
	int		d;
	double	v = random_normal(0.5, 0.25);
	double	l = v <= 0.5 ? v : 1.0 - v;
			
	for (d = 0; d < dim; d++)
		x[d] = v;
		
	for (d = 0; d < dim; d++)
	{
		double h = random_equal(-l, l);
		x[d] += h;
		x[(d + 1) % dim] -= h;
	}
} while (!is_vector_ok(dim, x));
\end{lstlisting}

Figure \ref{fig:density-2d-a2d1e5} shows an anti-correlated dataset
with 100k tuples for $d = 2$.
\end{itemize}

\begin{figure}[htbp]
\centering
\sbox{\tempbox}{\includegraphics[width=100mm]{plots-density/density-2d-a2d1e5}}%
\subfloat[Density Plot]{\usebox{\tempbox}}%
\subfloat[Statistics]{%
\begin{minipage}[b]{38mm}%
\vbox to \ht\tempbox{%
\vfil
\begin{tabular}[b]{r|rr}
	& d1 	& d2 \\
\hline
mean	& 0.500 & 0.500 \\
var	& 0.063 & 0.063 \\
\hline
cor	& d1	& d2 \\
\hline
d1	& 1.000 & -0.944 \\
d2	& -0.9444 & 1.000 \\
\end{tabular}
\vfil
}
\end{minipage}
}
\caption{Anti-correlated dataset (100k tuples)}%
\label{fig:density-2d-a2d1e5}%
\end{figure}

For the very details of the random dataset generator, please have a
look at the implementation which is available from \citep{Eder2007a}.

\subsubsection{As command line utility}

The most benifitial use case for the command line version of the
random dataset generator is to pipe its output directly into the
database. The usage message explains how to use the command line
utility:

\begin{interactive}
\shprompt{randdataset -?}
Test Data Generator for Skyline Operator Evaluation
Usage: randdataset (-i|-c|-a) -d DIM -n COUNT [-s SEED] [-p] [-S] [-h|-?]

Options:
       -i       independent (dim >= 1)
       -c       correlated (dim >= 2)
       -a       anti-correlated (dim >= 2)

       -d DIM   dimensions >=1
       -n COUNT number of vectors
       -I       unique id for every vector
       -p PAD   add a padding field, PAD characters long

       -C       generate SQL COPY statement
       -R       generate SQL CREATE TABLE statement
       -T NAME  use NAME instead of default table name

       -s SEED  set random generator seed to SEED

       -S       output stats to stderr

       -h -?    display this help message and exit

Examples:
       randdataset -i -d 3 -n 10 -I -R
       randdataset -a -d 2 -n 100 -S
\end{interactive}

An invocation of \texttt{randdataset} suitable to pipe it directly
into \texttt{psql}, i.e. load it into database, could look like:

\begin{interactive}
\shprompt{randdataset -i -d 3 -n 10 -I -R}
DROP TABLE IF EXISTS "i3d10";
CREATE TABLE "i3d10" (id int, d1 float, d2 float, d3 float);
COPY "i3d10" (id, d1, d2, d3) FROM STDIN DELIMITERS ',' CSV QUOTE '''';
1,0.000000000000000e+00,6.900010321708401e-01,5.054183972559023e-01
2,5.914905399975788e-01,5.547849133400177e-01,3.784288188342139e-01
...\rcomment{7 rows omitted}
10,8.585111004572880e-01,9.898449857671955e-02,8.770675234855467e-01
\ttbackslash.
\end{interactive}

\subsubsection{PostgreSQL Random Dataset Generator Function}

To be able to generate test datasets on the fly, i.e. with out
explicitly creating tables and filling them up, we create a PostgreSQL
module which implements the functionality of \texttt{randdataset} as a
set returning function. To create, backup and restore a test database
with an appropriate set of test tables can be very time
consuming. Having such a function at had is useful in many situations,
all it takes is run PostgreSQLs \texttt{initdb} and install the set
returning function. We did so many times when merging PostgreSQL
8.3-devel branch into our branch, which often made it necessary to
re-\texttt{initdb}. Especially for regression tests and during
debugging this function was very handy. PostgreSQLs concept of
\postgresdocu{functions-srf.html}{set returning functions} allows to
issue queries as such:

\begin{interactive}
\sqlprompt{SELECT * FROM generate_series(2,4);}
 generate_series
-----------------
               2
               3
               4
(3 rows)
\end{interactive}

This concept of set returning functions is quite flexible and allows
also to return complex data types such as records. To test drive this
PostgreSQL 'contrib' module (see
\srcref(contrib/randdataset)), without installing it, even with
installing PostgreSQL visit our webinterface at
\url{http://skyline.dbai.tuwien.ac.at/}. To install it onto your
PostgreSQL installation follow the instructions
\srcref{contrib/randdataset/README.randdataset}. Once installed the
function can be used as follows:

\begin{interactive}
\sqlprompt{SELECT rds.id, rds.d1, rds.d2 FROM}\rcomment{columns are refered by name}
\sqlpromptcont{pg_rand_dataset('indep', 2, 10, 0) AS}\rcomment{2 dim independent dataset with 10 tuples}
\sqlpromptcont{rds(id int, d1 float, d2 float);}\rcomment{define names and types}
 id |         d1         |         d2
----+--------------------+--------------------
  1 |  0.170828036112165 |  0.749901980510867
  2 | 0.0963716553972902 |  0.870465227342427
...\rcomment{7 rows omitted}
 10 |  0.715538595204958 | 0.0830042460388524
(10 rows)

\sqlprompt{SELECT rds.* FROM}
\sqlpromptcont{pg_rand_dataset('corr', 3, 10, 0) AS}\rcomment{3 dim, correleted, 10 tuples}
\sqlpromptcont{rds(id int, d1 float, d2 float, d3 float);}
 id |        d1         |        d2         |        d3
----+-------------------+-------------------+-------------------
  1 | 0.482522432069401 | 0.327330244422693 | 0.207248995528228
  2 | 0.448836206689892 | 0.512027726159258 | 0.600054676092416
...\rcomment{7 rows omitted}
 10 | 0.319189108559988 | 0.407713612758059 |  0.30165467053249
(10 rows)

\sqlprompt{SELECT rds.* FROM}
\sqlpromptcont{pg_rand_dataset('anti', 3, 20, 1) AS}\rcomment{3 dim, anti-correlated, 20 tuples, seed 1}
\sqlpromptcont{rds(id int, d1 float, d2 float, d3 float);}
\comment{output ommit, as it is similar to above, except other distribution, more tuples, and another inital seed is used}
\end{interactive}

\noindent
The general signatur for \inlinesql{pg\_rand\_dataset} is:
\begin{interactive}
FUNCTION pg_rand_dataset(disttype text, dim int, rows int, seed int)
RETURNS setof record
\end{interactive}

\noindent
Where the arguments have following meaning:
\begin{itemize}
\item \texttt{disttype} specifies the distribution type (see section \ref{sec:corr-anti-indep}), allowed values are \texttt{'indep'}, \texttt{'corr'}, and \texttt{'anti'}

\item \texttt{dim} specifies the number of dimensions, allowed values are 1 upto 20 

\item \texttt{rows} specifies the number of tuples that should be returned, and 

\item \texttt{seed} is the seed for the random generator
\end{itemize}

We ensured that calling \inlinesql{pg\_rand\_dataset} with the same
arguments will always return the same result set. In the PostgreSQL
terminology this property of a function is called \texttt{IMMUTABLE}
(see PostgreSQL documentation on
\postgresdocu{xfunc-volatility.html}{Function Volatility Categories}).

To make the usage more comfortable we defined a set of wrapper
functions \texttt{rds$k$d} for the dimenions $k \in \{1, \ldots,
20\}$, they allowed us to issue the same queries as above in the
following why (see \srcref{contrib/randdataset/randdataset.sql.in}):

\begin{interactive}
\sqlprompt{SELECT rds.* FROM rds2d('indep', 10, 0) AS rds;}
\rcomment{output completely omitted, as it is the same as above}

\sqlprompt{SELECT rds.* FROM rds3d('corr', 10, 0) AS rds;}
\rcomment{same here}

\sqlprompt{SELECT rds.* FROM rds3d('anti', 20, 0) AS rds;}
\rcomment{same here}
\end{interactive}


\subsubsection{Buffer for Set returning function}

In the PostgreSQL execution engin a function scan node is responsible
for retrieving tuples from a set returning function. The current
implementation reads all the tuples from the set returning function
and stores them in a \texttt{tuplestore} before returning the first
tuple to the caller. A \texttt{tuplestore} maintains an in memory
buffer once it runs out of memory the remaining tuples are written to
a tempfile. The size of the in memory buffer is controlled through the
configuration variable \texttt{work\_mem}. The default value is
1024~KB. This configuration variable is also used to determine the amout
of RAM used for sort operations, for merge joins, hash joins and many more.
So RAM used for a single complex query can by multiple times the value of 
\texttt{work\_mem}.
In our setting we use the configuration variable \texttt{work\_mem}
for the sort operation in SFS and as the default tuple window size for
skyline algorithms that require a tuple window. In the following query
PostgreSQL call \texttt{generate\_series} a million times and will
discard all tuples except one due to the
\texttt{LIMIT 1}-clause.

\begin{interactive}
\sqlprompt{SELECT * FROM generate_series(1,1000000) LIMIT 1;}
 generate_series
-----------------
               1
(1 row)
\end{interactive}

This behavior is not desirable, at least we want that the tuples do
not get swapped out to disk as
\texttt{tuplestore}'s-\texttt{work\_mem} gets full, since for parts
of our experiments we were not willing to pay I/O penalty as we were
studing just the CPU bounded behavior of the skyline algorithms.

On the other hand we do not want to increase \texttt{work\_mem}, as
this would as mentioned above influence the sort operation and the size
of the tuple window for the skyline algorithms. Therefore we decided
to introduce a new configuration variable
\texttt{function\_scan\_work\_mem}, solely for the \texttt{tuplestore}
in the function scan node. The following utility query sets this
configuration variable to 100~MB;

\begin{interactive}
\sqlprompt{SET function_scan_work_mem  = 102400;}
\end{interactive}

\todo{}{link to the patch function\_scan\_work\_mem.diff}



\section{Parameter Space}
\todo{see \citep{Gray1993}}{}
\todo{}{rework}

There is a large number of parameters that can be varied:

\begin{itemize}
\item \emph{size of dataset} (100?, 1000?, 10000, 100000, 1000000)
\item \emph{number of dimensions} (1-15, or even 10 is enough)
\item \emph{data distribution} (indep, corr, anti)
\item \emph{data source} (disk, set returning function)

in case the data are stored on disk
\begin{itemize}
\item \emph{sequencial scan vs. index scan} SFS can benefit from index scan (ommit sort phase), BNL and SFS could benefit from a index scan if DIFF groups are used.
\item \emph{sequence of tuples in tuple stream} (random, high entropy first/last) for BNL and EF if a very good tuple is very early in the tuple stream it will eliminate a lot of tuples in a very early stage
\end{itemize}
\item \emph{methods}

\begin{itemize}
\item as SQL statement
\item special case 1 dim distinct
\item special case 1 dim 
\item special case 2 dim (needs sort presort or access path)
\item BNL
\item SFS
\item EF+SFS=LESS
\item EF+BNL
\end{itemize}

\item window size
\item window policy (prepend, append, entropy)
\item entropy needs stats for scaling to (0,1)

\end{itemize}


\begin{itemize}
\item use 90\% percentile (\citep{Gray1993}[page 315]) vs, average / variance (box-plots?)
\item describe software (operating system: Windows XP + SP 2, Microsoft Visual Studio 2005 + SP1, based on PostgreSQL 8.3.0) and hardware (CPU, RAM, Disk config, File System) used for benchmarking

\item describe the configuration of PostgreSQL (flags used for \texttt{configure --enable-asserts --enable-checks, ...}, it is recommended to turn asserts and co. off for benchmarking
\end{itemize}


\section{Experimental Environment}
\todo{}{}


\section{Comparisons and Analysis}
\label{sec:analysis}
We measure the time performance with respect to three parameters:
dimension, data cardinality, and data distribution.  We tested on the
following three data distributions: independent (i), correlated (c),
and anti-correlated (a).  For the other two factors "dimension" and
"cardinality", one has been fixed during each experiment.  Thus all
the plots are two dimensional.

\subsection{Time performance w.r.t. dimension}

\begin{figure}[htbp]
\centering%
\begin{minipage}{\onecolumnwidth}%
\subplotprofile[Independent dataset (100k tuples)]{bnl-wp-dim-i-100000}\\
\subplotprofile[Correlated dataset (100k tuples)]{bnl-wp-dim-c-100000}\\
\subplotprofile[Anti-correlated dataset (100k tuples)]{bnl-wp-dim-a-100000}%
\caption{Comparing runtime for different methods (100k tuples)}%
\label{fig:all-dim}%
\end{minipage}%
\hspace{\columnsep}%
\begin{minipage}{\onecolumnwidth}%
\subplotprofile[Independent dataset (100k tuples)]{all-dim-i-100000}\\
\subplotprofile[Correlated dataset (100k tuples)]{all-dim-c-100000}\\
\subplotprofile[Anti-correlated dataset (100k tuples)]{all-dim-a-100000}%
\caption{Absolute timing for different physical skyline operators (100k tuples)}%
\label{fig:all-dim-absolute}
\end{minipage}%
\end{figure}

For this set of experiments we fix the number of tuples of the input data.
Note that generally the absolute time measurements are not proportional 
throughout the dimensions, we thus deploy the relative values by setting one measurement as
the reference. 
In Figure~\ref{fig:all-dim-absolute}
we illustrate the absolute time measurements which are corresponding to
the relative values in Figure~\ref{fig:all-dim}. 
In the rest of the experiments, we only provide relative time measurements.

\subsubsection{Special case: 1 dimensional skylines}
\todo{}{}

\subsubsection{Special case: 2 dimensional skylines}
\todo{}{}

\subsubsection{Big datasets}
\label{sec:big-datasets}
Figure~\ref{fig:all-dim} shows the time performance of the skyline
algorithms vs. dimension with 100k tuples. It shows clearly that the
SFS+EF algorithm has the best time performance with all the data
distributions.  This conforms with the results in \cite{Godfrey2007},
where it was shown that LESS outperforms the SFS algorithm with 1M
tuples.

We also note that SFS performs extremely poor as the dimension is less
than six for independent and anti-correlated data, and even worse for
correlated data.  This can be justified that if the dimension is low,
the skyline selectivity factor\footnote{selectivity factor = skyline
tuples / input tuples. A low selectivity factor means high
selectivity.}  is low as well. Therefore, EF operation is effective,
i.e., a number of tuples could be removed at this stage. However, this
does not explain why SFS performs worse than BNL on datasets of low
dimensions. This can be clarified when considering the absolute time
measurement in Figure~\ref{fig:all-dim-absolute}.  It is shown that
the sorting routine of SFS has a nearly constant cost for all
dimensions. Therefore, for low dimensional datasets, the sorting cost
is dominant.

BNL+EF performs consistently better than BNL, due to the low skyline
selectivity factor for datasets with 100k tuples
(cf. Figure~\ref{fig:sf}).  As far as the window policy is concerned,
\emph{entropy} has consistently better performance for all the
algorithms.

\subsubsection{Small datasets}
\label{sec:small-datasets}

\begin{figure}[htbp]
\centering%
\begin{minipage}{\onecolumnwidth}%
\subplotprofile[Independent dataset]{presort-i}\\
\subplotprofile[Correlated dataset]{presort-c}\\
\subplotprofile[Anti-correlated dataset]{presort-a}%
\caption{Absolute timing for different physical skyline operators 
in the 2 dimensional case}%
\end{minipage}%
\hspace{\columnsep}%
\begin{minipage}{\onecolumnwidth}%
\subplotprofile[Independent dataset (1k tuples)]{bnl-wp-dim-i-1000}\\
\subplotprofile[Correlated dataset (1k tuples)]{bnl-wp-dim-c-1000}\\
\subplotprofile[Anti-correlated dataset (1k tuples)]{bnl-wp-dim-a-1000}%
\caption{Comparing runtime for different methods (1k tuples)}
\label{fig:all-dim-onek}
\end{minipage}%
\end{figure}

Figure~\ref{fig:all-dim-onek}
depicts the time-dimensionality performance regarding to datasets with 1k number of tuples.
One interesting observation is that the performance of SFS 
is surprisingly better than others, except for the extremely low dimension values
(three for independent, anti-correlated, and six for correlated distributions).
As illustrated by Figure~\ref{fig:sf}, 
there exists a causal relation with the skyline selectivity factors.
It shows clearly that as the data cardinality decreases,
the skyline selectivity factor increases. Therefore, in general, the EF operator is less effective 
with lower data cardinalities. To be more accurate, if the skyline selectivity factor
is higher than 0.1, the benefit gained from EF is marginal. 
This is confirmed by the results shown in Figure~\ref{fig:all-dim} as well.

The result is somehow contradictory to the claim that SFS+EF should 
perform consistently better than SFS, because at the EF stage there should be always 
some tuples eliminated. However, one should not ignore the cost of the EF operation,
where comparisons are executed. Moreover, if the \emph{entropy} window 
policy is applied, the time consumption is even higher. Hence, there exist
data settings where EF does not pay off anymore.

\subsection{Time performance w.r.t. cardinality}

To better understand the time performance of the skyline algorithm
with respect to the data cardinality, 
we conducted experiments for each dimension $k \in \{2, \ldots, 15\}$
with the number of tuples ranging from 100 to 100k. 
For each data distribution we have chosen four to five representative
dimension values.
Figure~\ref{fig:inde}, \ref{fig:corre}, and \ref{fig:anti}
illustrate the test results for independent, correlated,
and anti-correlated datasets, respectively.

Surprisingly, the \emph{rule of the selectivity factor} 
is proven to be true in all the datasets. 
That is, 
if the selectivity factor is higher than 0.1, the elimination filter
does not have any advantage. 

\subsubsection{Independent and anti-correlated datasets}
Let us first consider the independent datasets (Figure~\ref{fig:inde}).
As the dimension is higher than four, SFS is superior for all datasets,
except for data cardinality of 50k and 100k, where SFS+EF outperforms SFS.
If we examine again the selectivity factor for independent datasets in Figure~\ref{fig:sf},
these datasets are in the category where the selectivity factor 
is higher than 0.1. This result confirms our observation in Section~\ref{sec:small-datasets}.
Note that the same observation holds for BNL+EF vs. BNL as well.

With dimension three there is an exception, where BNL performs best.
This can be justified as follows: 
the sorting cost remains constant w.r.t. dimensions,
thus it becomes dominant with low dimension (such as three). 

The performance of anti-correlated datasets in Figure~\ref{fig:anti} 
behaves similarly to that of independent datasets, 
thus the above analysis can be applied as well.

\subsubsection{Correlated datasets}
For correlated datasets in Figure~\ref{fig:corre}, SFS+EF is superior
with a few exceptions. This again, can be perfectly explained by
the selectivity factors for correlated datasets (cf. Figure~\ref{fig:sf-c}).
Except for the data cardinality of 100 and 500, all
the selectivity factors are remarkably low (most of them are less than 0.1),
thus the EF operation pays off.

\begin{figure}[htbp]
\centering%
\subplotprofile[3 dim (independent)]{bnl-wp-rows-i-03}%
\hspace{\columnsep}%
\subplotprofile[4 dim (independent)]{bnl-wp-rows-i-04}\\
\subplotprofile[6 dim (independent)]{bnl-wp-rows-i-06}%
\hspace{\columnsep}%
\subplotprofile[9 dim (independent)]{bnl-wp-rows-i-09}\\
\subplotprofile[15 dim (independent)]{bnl-wp-rows-i-15}%
\caption{Comparing runtime for independent datasets}%
\label{fig:inde}%
\end{figure}

\begin{figure}[htbp]
\centering%
\subplotprofile[3 dim (correlated)]{bnl-wp-rows-c-03}%
\hspace{\columnsep}%
\subplotprofile[5 dim (correlated)]{bnl-wp-rows-c-05}\\
\subplotprofile[8 dim (correlated)]{bnl-wp-rows-c-08}%
\hspace{\columnsep}%
\subplotprofile[15 dim (correlated)]{bnl-wp-rows-c-15}%
\caption{Comparing runtime for correlated datasets}%
\label{fig:corre}%
\end{figure}


\begin{figure}[htbp]
\centering%
\subplotprofile[3 dim (anti-correlated)]{bnl-wp-rows-a-03}%
\hspace{\columnsep}%
\subplotprofile[4 dim (anti-correlated)]{bnl-wp-rows-a-04}\\
\subplotprofile[7 dim (anti-correlated)]{bnl-wp-rows-a-07}%
\hspace{\columnsep}%
\subplotprofile[15 dim (anti-correlated)]{bnl-wp-rows-a-15}%
\caption{Comparing runtime for anti-correlated datasets}%
\label{fig:anti}%
\end{figure}


\begin{figure}[htbp]
\centering%
\begin{minipage}{\onecolumnwidth}%
\subplotlabeledprofile{Independent dataset (100k tuples)}{sfs-index-i-100000}{fig:sfs-index-i}\\
\subplotlabeledprofile{Correlated dataset (100k tuples)}{sfs-index-c-100000}{fig:sfs-index-c}\\
\subplotlabeledprofile{Anti-correlated dataset (100k tuples)}{sfs-index-a-100000}{fig:sfs-index-a}%
\caption{Relative timing for SFS/SFS+EF when using index access paths (100k tuples)}%
\label{fig:sfs-index}%
\end{minipage}%
%\hspace{\columnsep}%
%\begin{minipage}{\onecolumnwidth}%
%\subplotlabeledprofile{independent dataset}{selectivity-dim-i}{fig:sf-i}\\
%\subplotlabeledprofile{correlated dataset}{selectivity-dim-c}{fig:sf-c}\\
%\subplotlabeledprofile{anti-correlated dataset}{selectivity-dim-a}{fig:sf-a}%
%\caption{Skyline operator selectivity factor on our test datasets}%
%\label{fig:sf}%
%\end{minipage}
\end{figure}


\begin{figure}[htbp]
\centering%
\begin{minipage}{\onecolumnwidth}%
\subplotlabeledprofile{Independent dataset}{selectivity-dim-i}{fig:sf-i}\\
\subplotlabeledprofile{Correlated dataset}{selectivity-dim-c}{fig:sf-c}\\
\subplotlabeledprofile{Anti-correlated dataset}{selectivity-dim-a}{fig:sf-a}%
\end{minipage}%
\hspace{\columnsep}%
\begin{minipage}{\onecolumnwidth}%
\subplotlabeledprofile{Independent dataset}{selectivity-rows-i}{fig:sf-rows-i}\\
\subplotlabeledprofile{Correlated dataset}{selectivity-rows-c}{fig:sf-rows-c}\\
\subplotlabeledprofile{Anti-correlated dataset}{selectivity-rows-a}{fig:sf-rows-a}%
\end{minipage}
\caption{Skyline operator selectivity factor on our test datasets}%
\label{fig:sf}%
\end{figure}


\begin{figure}[htbp]
\centering
\subplotlabeledprofile{1k tuples}{ef-eff-dim-1000-efws8}{fig:ef-eff-1k}\\
\subplotlabeledprofile{10k tuples}{ef-eff-dim-10000-efws8}{fig:ef-eff-10k}\\
\subplotlabeledprofile{100k tuples}{ef-eff-dim-100000-efws8}{fig:ef-eff-100k}%
\caption{Effectiveness of elimination filter (EF) for varying dimensions}%
\label{fig:ef-eff}%
\end{figure}

\subsection{SFS using indexes}
The idea is to leverage the index structure for SFS in order to avoid an explicit sort.
For SFS+EF w/ index this is illustrated in Figure~\ref{fig:qp-sfs-index-ef}.
It is up to the query optimizer to decide by means of cost estimation 
whether to use an index or not.
We analyzed the usage of indexes for SFS in detail for 100k tuples 
(see Figure~\ref{fig:sfs-index}).

It turns out that SFS w/ index consistently outperforms SFS, 
independent from the window policy used, with a single exception (cf. 
Figure~\ref{fig:sfs-index-a} when dim=6). 
This is clearly an argument for using an index.

However, SFS+EF w/ index performs worse than SFS w/ index. 
This is somehow counterintuitive, because for 100k tuples 
SFS+EF performs better than SFS, as we have discussed
in Section~\ref{sec:big-datasets} (cf. Figure~\ref{fig:all-dim}).
We argue that, the effectiveness of EF deteriorates
in the presence of the index structure.
The data is physically ordered according to one of the indexed attributes,
which is not guaranteed to be beneficial for the elimination filtering.
Therefore, one should be careful with applying EF in the presence of index,
even on the datasets with low selectivity factors.
%
The only significant exception is for correlated data, window policy append, and dim 
$\le 3$ (cf. Figure~\ref{fig:sfs-index-c}).
We argue this is due to the general low selectivity factor and high EF effectiveness in 
this case (cf. Figure~\ref{fig:sf-c} and \ref{fig:ef-eff-100k}).

In all aspects, SFS w/ index and SFS+EF w/ index are outperformed
by SFS+EF using window policy entropy or prepend. This can
be explained with the same argument as above, EF eliminates
so many tuples prior to sorting that this becomes cheaper than
using an index.

%\pagebreak[4]
\subsection{Window policy}
All experimental results show that the \emph{entropy} is
the most efficient and effective window policy.
One might notice that on correlated datasets, the \emph{prepend}
window policy performs the worst in the SFS algorithm. 
The explanation is obvious: if the correlated data is sorted,
the most effective skyline tuples (that is, the tuples dominate 
most of the other tuples) tend to enter the widow earlier. 
However with the prepend policy, these tuples are successively pushed
to the end of the window, which results in high time costs
for checking whether a new tuple is dominated by
the tuples in the window.
Figure \ref{fig:ef-eff} shows that \emph{entropy} is
the most effective EF window policy. 

\subsection{Mixing window policies}
\todo{show some effects of using different window policies for EF and BNL/SFS nodes}{}

\subsection{Window Size}
\label{sec:analysis-window-size}
\todo{}{}

\subsection{EF Window size}
\todo{}{}



%%
%% CHAPTER: Future Work
%%



\chapter{Future work}

\section{Index-based algorithms}

In the future work we plan to implement and evaluate index-based algorithms 
such as 
{\em Index} \cite{Tan2001}, 
{\em Nearest Neighbor} (NN) \cite{Kossmann2002}, and
{\em Branch and Bound} (BBS) \cite{Papadias2003, Papadias2005}.

\section{Speedup Tuple Comparison}
We believe the concept of EF is very promising and plan to further
improve its efficiency and effectiveness, e.g. to integrate it as a
filter in the index scan code, to use other data structures and
policies for the EF window, and to optimize the order of attributes
when comparing two tuples.

\section{Index Scan and SFS}
As for SFS algorithms using indexes, what remains open is to
investigate the behavior in case all skyline attributes and attributes
in the select clause are part of the index, such that it suffices only
to access the indexes for the query processing.  We believe this could
yield good results.

\section{Index scan for one dimensional skylines}
Since one dimensional skylines are a little bit of limited use anyway
we did not yet make an attempt to make use of an suitable index for
skyline computation in the one dimensional case. The computation of
distinct and non-distinct one dimensional skyline could be speedup by
performing an index scan. In the distinct case start at the minimum or
maximum respectivly and read a sinlge tuple. For the non-distinct case
start at the right end of the index and read as long as the value does
not change.

\section{Speedups for low cardinalty domains}
%
use special algorithms if we deal with domains with small
cardinalites, \citep{Preisinger2006, Preisinger2007, Morse2007}

\section{Speedups for \inlinesql{SKYLINE OF DIFF}}
%
Use a seperate tuple window for each \inlinesql{SKYLINE OF DIFF}
group, so only the tuples with the same values on the
\inlinesql{SKYLINE OF DIFF} attributes have to be compared to each
other. This reduction of comparision would yield an overall speedup.
In order to avoid an unbounded number of tuple windows instead of
having a tuple window for each \inlinesql{SKYLINE OF DIFF} group
hashing could be engaded, i.e. allocate a fixed number of tuple
windows and hash each \inlinesql{SKYLINE OF DIFF} group into one tuple
window.

\section{Extensions}

\subsection{Sampling}

In the absence of statistics for the relation in questions, sampling
could be engadged. \todo{cite}{Chaurduri2006}

\subsection{$K$-skyband}
implement $K$-skyband (maintaine dominance count in tuple window) do
so for BNL and SFS.

\subsection{$k$-dominance skyline}
\todo{is this easy possible?}{}



%%%
%%% CHAPTER: Summary
%%%



\chapter{Summary}

In this paper we presented the experiments with skyline algorithms
applied on the open source RDBMS PostgreSQL.

From our experimental results we were able to expose several findings
which are difficult to be verified theoretically.  There are: (1) the
elimination filter is effective only if the selectivity factor of the
dataset is not more than $0.1$; (2) for datasets up to $500$ tuples
and of relative small dimension (e.g. up to five), BNL performs the
best in all aspects.



